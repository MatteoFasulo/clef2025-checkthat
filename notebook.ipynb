{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10881030,"sourceType":"datasetVersion","datasetId":6742324,"isSourceIdPinned":false}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Subjectivity in News Articles\n\n## Group:\n- Luca Babboni - luca.babboni2@studio.unibo.it\n- Matteo Fasulo - matteo.fasulo@studio.unibo.it\n- Luca Tedeschini - luca.tedeschini3@studio.unibo.it\n\n## Description\n\nThis notebook addresses Task 1 proposed in [CheckThat Lab](https://checkthat.gitlab.io/clef2025/) of CLEF 2025. In this task, systems are challenged to distinguish whether a sentence from a news article expresses the subjective view of the author behind it or presents an objective view on the covered topic instead.\n\nThis is a binary classification tasks in which systems have to identify whether a text sequence (a sentence or a paragraph) is subjective (SUBJ) or objective (OBJ).\n\nThe task comprises three settings:\n\n* Monolingual: train and test on data in a given language\n* Multilingual: train and test on data comprising several languages\n* Zero-shot: train on several languages and test on unseen languages\n\ntraining data in five languages:\n* Arabic\n* Bulgarian\n* English\n* German\n* Italian\n\nThe official evaluation is macro-averaged F1 between the two classes.","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install -U transformers[torch] bitsandbytes trl peft sacremoses ctranslate2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.kill(os.getpid(), 9)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nimport os\nimport gc\nfrom pathlib import Path\n\nimport csv\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\n\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nfrom sentence_transformers import SentenceTransformer\nfrom datasets import Dataset\nfrom huggingface_hub import notebook_login\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    Trainer, \n    TrainingArguments, \n    DataCollatorWithPadding, \n    BitsAndBytesConfig,\n    pipeline, \n    get_linear_schedule_with_warmup\n)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T19:21:52.035009Z","iopub.execute_input":"2025-03-05T19:21:52.035695Z","iopub.status.idle":"2025-03-05T19:21:52.042364Z","shell.execute_reply.started":"2025-03-05T19:21:52.035653Z","shell.execute_reply":"2025-03-05T19:21:52.041149Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"SEED = 42\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T19:21:52.046484Z","iopub.execute_input":"2025-03-05T19:21:52.046830Z","iopub.status.idle":"2025-03-05T19:21:52.093182Z","shell.execute_reply.started":"2025-03-05T19:21:52.046793Z","shell.execute_reply":"2025-03-05T19:21:52.092196Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"np.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T19:21:52.094300Z","iopub.execute_input":"2025-03-05T19:21:52.094644Z","iopub.status.idle":"2025-03-05T19:21:52.116671Z","shell.execute_reply.started":"2025-03-05T19:21:52.094613Z","shell.execute_reply":"2025-03-05T19:21:52.115370Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class Subjectivity:\n    def __init__(self, data_folder: str = 'data', seed: int = 42, device: str = 'cuda'):\n        self.seed = seed\n        self.device = device\n        self.languages = [language for language in os.listdir(data_folder)]\n\n        dataset = self.create_dataset(data_folder=data_folder)\n        self.dataset = dataset\n        \n        train, dev, test = self.get_splits(dataset, print_shapes=True)\n        self.train = train\n        self.dev = dev\n        self.test = test\n\n        self.all_data = self.get_per_lang_dataset()\n        \n\n    def create_dataset(self, data_folder: str = 'data'):\n        dataset = pd.DataFrame(columns=['sentence_id','sentence','label','lang','split'])\n        for language in os.listdir(data_folder):\n            for filename in os.listdir(f\"{data_folder}{os.sep}{language}\"):\n                if '.tsv' in filename:\n                    abs_path = f\"{data_folder}{os.sep}{language}{os.sep}{filename}\"\n                    df = pd.read_csv(abs_path, sep='\\t', quoting=csv.QUOTE_NONE)\n                    if 'solved_conflict' in df.columns:\n                        df.drop(columns=['solved_conflict'], inplace=True)\n                    df['lang'] = language\n                    df['split'] = Path(filename).stem\n                    dataset = pd.concat([dataset, df], axis=0)\n        return dataset\n\n    def get_splits(self, dataset: pd.DataFrame, print_shapes: bool = True):\n        train = dataset[dataset['split'].str.contains('train')].copy()\n        dev = dataset[(dataset['split'].str.contains('dev')) & ~(dataset['split'].str.contains('dev_test'))].copy()\n        test = dataset[dataset['split'].str.contains('dev_test')].copy()\n\n        # encode the target variable to int (0: obj; 1: subj)\n        train.loc[:, 'label'] = train['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n        dev.loc[:, 'label'] = dev['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n        test.loc[:, 'label'] = test['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n\n        # cast to int\n        train['label'] = train['label'].astype(int)\n        dev['label'] = dev['label'].astype(int)\n        test['label'] = test['label'].astype(int)\n\n        if print_shapes:\n            print(f\"Train: {train.shape}\")\n            print(f\"Dev: {dev.shape}\")\n            print(f\"Test: {test.shape}\")\n            \n        return train, dev, test\n\n    def get_per_lang_dataset(self):\n        \"\"\"\n        dataset_dict = {\n            'english': {\n                'train': ...\n                'dev': ...\n                'test': ...\n            },\n        }\n        \"\"\"\n        dataset_dict = {}\n        for language in self.languages:\n            dataset_dict[language] = {}\n            # get the train data\n            dataset_dict[language]['train'] = self.train[self.train['lang']==language].copy()\n            # get the dev data\n            dataset_dict[language]['dev'] = self.dev[self.dev['lang']==language].copy()\n            # get the test data\n            dataset_dict[language]['test'] = self.test[self.test['lang']==language].copy()\n        return dataset_dict\n\n    def print_label_distrib(self, dataset: pd.DataFrame):\n        print(dataset['label'].value_counts(normalize=True))\n\n    def get_baseline_model(self, model_name: str = \"paraphrase-multilingual-MiniLM-L12-v2\"):\n        vect = SentenceTransformer(model_name)\n        self.vect = vect\n        return vect\n\n    def train_baseline_model(self, vect, train_data: pd.DataFrame, test_data: pd.DataFrame, solver: str = 'saga'):\n        model = LogisticRegression(class_weight=\"balanced\", solver=solver, random_state=self.seed)\n        model.fit(X=vect.encode(train_data['sentence'].values), y=train_data['label'].values)\n        predictions = model.predict(X=vect.encode(test_data['sentence'].values)).tolist()\n\n        # eval performances\n        perfs = self.evaluate_model(gold_values=test_data['label'].values, predicted_values=predictions)\n\n        return perfs\n\n    def get_tokenizer(self, model_card: str = \"microsoft/mdeberta-v3-base\"):\n        tokenizer = AutoTokenizer.from_pretrained(model_card)\n        self.tokenizer = tokenizer\n        return tokenizer\n\n    def get_model(self, model_card: str = \"microsoft/mdeberta-v3-base\", *args, **kwargs):\n        model = AutoModelForSequenceClassification.from_pretrained(model_card, *args, **kwargs)\n        self.model = model\n        return model\n\n    def get_class_weights(self, dataset: pd.DataFrame):\n        class_weights = compute_class_weight('balanced', classes=np.unique(dataset['label']), y=dataset['label'])\n        return class_weights\n\n    def evaluate_model(self, gold_values, predicted_values):\n        acc = accuracy_score(gold_values, predicted_values)\n        m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(gold_values, predicted_values, average=\"macro\",\n                                                                   zero_division=0)\n        p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(gold_values, predicted_values, labels=[1],\n                                                                   zero_division=0)\n    \n        return {\n            'macro_F1': m_f1,\n            'macro_P': m_prec,\n            'macro_R': m_rec,\n            'SUBJ_F1': p_f1[0],\n            'SUBJ_P': p_prec[0],\n            'SUBJ_R': p_rec[0],\n            'accuracy': acc\n        }","metadata":{"execution":{"iopub.status.busy":"2025-03-05T19:21:52.119445Z","iopub.execute_input":"2025-03-05T19:21:52.119817Z","iopub.status.idle":"2025-03-05T19:21:52.145030Z","shell.execute_reply.started":"2025-03-05T19:21:52.119778Z","shell.execute_reply":"2025-03-05T19:21:52.143651Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data_folder = '/kaggle/input/clef2025-checkthat/data' # data","metadata":{"execution":{"iopub.status.busy":"2025-03-05T19:21:52.146339Z","iopub.execute_input":"2025-03-05T19:21:52.146746Z","iopub.status.idle":"2025-03-05T19:21:52.177061Z","shell.execute_reply.started":"2025-03-05T19:21:52.146711Z","shell.execute_reply":"2025-03-05T19:21:52.176014Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"detector = Subjectivity(data_folder=data_folder, seed=SEED, device=device)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T19:21:52.178210Z","iopub.execute_input":"2025-03-05T19:21:52.178585Z","iopub.status.idle":"2025-03-05T19:21:52.471174Z","shell.execute_reply.started":"2025-03-05T19:21:52.178553Z","shell.execute_reply":"2025-03-05T19:21:52.470063Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: (6418, 5)\nDev: (2401, 5)\nTest: (2332, 5)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"detector.print_label_distrib(detector.train)\ndetector.print_label_distrib(detector.dev)\ndetector.print_label_distrib(detector.test)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T19:21:52.472237Z","iopub.execute_input":"2025-03-05T19:21:52.472592Z","iopub.status.idle":"2025-03-05T19:21:52.483182Z","shell.execute_reply.started":"2025-03-05T19:21:52.472564Z","shell.execute_reply":"2025-03-05T19:21:52.481786Z"},"trusted":true},"outputs":[{"name":"stdout","text":"label\n0    0.631349\n1    0.368651\nName: proportion, dtype: float64\nlabel\n0    0.612245\n1    0.387755\nName: proportion, dtype: float64\nlabel\n0    0.657376\n1    0.342624\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"notebook_login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = {}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L3700 (with some minor changes removing useless parts)\nclass CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, weights_dtype=torch.float32, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Ensure label_weights is a tensor\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, dtype=weights_dtype).to(self.args.device)\n        else:\n            self.class_weights = None\n\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        # Extract labels and convert them to long type for cross_entropy\n        labels = inputs.pop(\"labels\").long()\n\n        # Forward pass\n        outputs = model(**inputs)\n\n        # Extract logits assuming they are directly outputted by the model\n        logits = outputs.get('logits')\n\n        # Compute custom loss with class weights for imbalanced data handling\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss\n\ndef tokenize_text(texts):\n    return tokenizer(texts['sentence'], padding=True, truncation=True, max_length=256, return_tensors='pt')\n\ndef evaluate_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    acc = accuracy_score(labels, predictions)\n    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                                zero_division=0)\n    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                                zero_division=0)\n\n    return {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:21:55.706774Z","iopub.execute_input":"2025-03-05T19:21:55.707097Z","iopub.status.idle":"2025-03-05T19:21:55.715964Z","shell.execute_reply.started":"2025-03-05T19:21:55.707074Z","shell.execute_reply":"2025-03-05T19:21:55.714719Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Baseline Model (English)","metadata":{}},{"cell_type":"code","source":"vect = detector.get_baseline_model(model_name=\"paraphrase-multilingual-MiniLM-L12-v2\")\nvect","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.all_data['english']['train'], detector.all_data['english']['test'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model (italian)","metadata":{}},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.all_data['italian']['train'], detector.all_data['italian']['test'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model (multilingual)","metadata":{}},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.train, detector.test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (Arabic)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'arabic'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (Bulgarian)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'bulgarian'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (German)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'german'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (italian)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'italian'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (multilingual)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.train)\ndev_data = Dataset.from_pandas(detector.dev)\ntest_data = Dataset.from_pandas(detector.test)\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-multilingual\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults['multi'] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix (multilingual)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(results).T.sort_values(by='macro_F1', ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# ModernBERT-base (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"answerdotai/ModernBERT-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"ModernBERT-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults['english-modern-bert'] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix (english-modern-bert)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(results).T.sort_values(by='macro_F1', ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Llama-3.2-1B (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"meta-llama/Llama-3.2-1B\" # meta-llama/Meta-Llama-3-8B","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit = False, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_card, add_prefix_space=True)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card,\n    quantization_config=quantization_config,\n    num_labels=2,\n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-4\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=\"Llama-3.2-1B-subjectivity-english\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions, labels, _ = trainer.predict(test_data)\nevaluate_metrics((predictions, labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Deepseek-llm-7b-base","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"deepseek-ai/deepseek-llm-7b-base\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit = True, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\nlora_config = LoraConfig(\n    r = 8, # the dimension of the low-rank matrices\n    lora_alpha = 32, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_card)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card,\n    quantization_config=quantization_config,\n    num_labels=2,\n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 4\nlr = 1e-4\nweight_decay = 0.1\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=\"deepseek-llm-7b-base-subjectivity-english\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    #gradient_accumulation_steps=16,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n    weights_dtype=torch.float16,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions, labels, _ = trainer.predict(test_data)\nevaluate_metrics((predictions, labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test - Translating Arab to English","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:33:45.272585Z","iopub.execute_input":"2025-03-05T19:33:45.272931Z","iopub.status.idle":"2025-03-05T19:33:45.874047Z","shell.execute_reply.started":"2025-03-05T19:33:45.272894Z","shell.execute_reply":"2025-03-05T19:33:45.873094Z"}},"outputs":[{"name":"stdout","text":"Model deleted!\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"67"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"model_card = \"answerdotai/ModernBERT-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:33:45.875299Z","iopub.execute_input":"2025-03-05T19:33:45.875560Z","iopub.status.idle":"2025-03-05T19:33:46.151650Z","shell.execute_reply.started":"2025-03-05T19:33:45.875538Z","shell.execute_reply":"2025-03-05T19:33:46.150805Z"}},"outputs":[{"name":"stderr","text":"Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"language = 'arabic'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:33:47.291770Z","iopub.execute_input":"2025-03-05T19:33:47.292098Z","iopub.status.idle":"2025-03-05T19:33:47.296430Z","shell.execute_reply.started":"2025-03-05T19:33:47.292074Z","shell.execute_reply":"2025-03-05T19:33:47.295176Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"!ct2-transformers-converter --model Helsinki-NLP/opus-mt-ar-en --output_dir opus-mt-ar-en","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ctranslate2\nimport transformers\n\ntranslator = ctranslate2.Translator(\"opus-mt-ar-en\", device='cuda')\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ar-en\")\n\ndef translate_text(raw_text):\n    source = tokenizer.convert_ids_to_tokens(tokenizer.encode(raw_text))\n    results = translator.translate_batch([source])\n    target = results[0].hypotheses[0]\n    translation = tokenizer.decode(tokenizer.convert_tokens_to_ids(target))\n    return translation\n\ntqdm.pandas() # display tqdm on pandas apply functions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['train']['translated_sentence'] = detector.all_data[language]['train']['sentence'].progress_apply(translate_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['dev']['translated_sentence'] = detector.all_data[language]['dev']['sentence'].progress_apply(translate_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['test']['translated_sentence'] = detector.all_data[language]['test']['sentence'].progress_apply(translate_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['train'] = pd.read_csv('/kaggle/working/train_ar.csv')\ndetector.all_data[language]['dev'] = pd.read_csv('/kaggle/working/dev_ar.csv')\ndetector.all_data[language]['test'] = pd.read_csv('/kaggle/working/dev_test_ar.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:33:51.122240Z","iopub.execute_input":"2025-03-05T19:33:51.122613Z","iopub.status.idle":"2025-03-05T19:33:51.172761Z","shell.execute_reply.started":"2025-03-05T19:33:51.122587Z","shell.execute_reply":"2025-03-05T19:33:51.171634Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"epochs = 6\nbatch_size = 16\nlr = 6e-5\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ndef tokenize_text(texts):\n    return tokenizer(texts['translated_sentence'], padding=True, truncation=True, max_length=256, return_tensors='pt')\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:33:52.902000Z","iopub.execute_input":"2025-03-05T19:33:52.902373Z","iopub.status.idle":"2025-03-05T19:33:53.857413Z","shell.execute_reply.started":"2025-03-05T19:33:52.902343Z","shell.execute_reply":"2025-03-05T19:33:53.856643Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8ccde56ba02432587d431713baacf01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/467 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50569e29dce648309a25ae8579efe711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/748 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6675ed8dcacc4870b2ac2ff2c3c2e394"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"ModernBERT-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:33:55.240064Z","iopub.execute_input":"2025-03-05T19:33:55.240465Z","iopub.status.idle":"2025-03-05T19:33:55.272003Z","shell.execute_reply.started":"2025-03-05T19:33:55.240436Z","shell.execute_reply":"2025-03-05T19:33:55.271141Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n    weights_dtype=torch.float32,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:34:01.623559Z","iopub.execute_input":"2025-03-05T19:34:01.623972Z","iopub.status.idle":"2025-03-05T19:34:01.858839Z","shell.execute_reply.started":"2025-03-05T19:34:01.623930Z","shell.execute_reply":"2025-03-05T19:34:01.857736Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:34:02.999912Z","iopub.execute_input":"2025-03-05T19:34:03.000271Z","iopub.status.idle":"2025-03-05T19:40:14.118199Z","shell.execute_reply.started":"2025-03-05T19:34:03.000232Z","shell.execute_reply":"2025-03-05T19:40:14.116623Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='613' max='918' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [613/918 06:04 < 03:01, 1.68 it/s, Epoch 4/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Macro F1</th>\n      <th>Macro P</th>\n      <th>Macro R</th>\n      <th>Subj F1</th>\n      <th>Subj P</th>\n      <th>Subj R</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.691858</td>\n      <td>0.449092</td>\n      <td>0.535261</td>\n      <td>0.522566</td>\n      <td>0.578856</td>\n      <td>0.444149</td>\n      <td>0.830846</td>\n      <td>0.479657</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.746310</td>\n      <td>0.436740</td>\n      <td>0.570905</td>\n      <td>0.518460</td>\n      <td>0.154506</td>\n      <td>0.562500</td>\n      <td>0.089552</td>\n      <td>0.578158</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.850804</td>\n      <td>0.517078</td>\n      <td>0.545775</td>\n      <td>0.534040</td>\n      <td>0.357827</td>\n      <td>0.500000</td>\n      <td>0.278607</td>\n      <td>0.569593</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.584200</td>\n      <td>1.636189</td>\n      <td>0.563007</td>\n      <td>0.578002</td>\n      <td>0.577030</td>\n      <td>0.571429</td>\n      <td>0.494545</td>\n      <td>0.676617</td>\n      <td>0.563169</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2241\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2242\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2639\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3092\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3093\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3188\u001b[0m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3189\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3859\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3862\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3962\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3964\u001b[0;31m             self.model.save_pretrained(\n\u001b[0m\u001b[1;32m   3965\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3966\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   3030\u001b[0m                 \u001b[0;31m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m                 \u001b[0;31m# joyfulness), but for now this enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3032\u001b[0;31m                 \u001b[0msafe_save_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3033\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3034\u001b[0m                 \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mserialize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":31},{"cell_type":"code","source":"predictions, labels, _ = trainer.predict(test_data)\nevaluate_metrics((predictions, labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:40:14.118863Z","iopub.status.idle":"2025-03-05T19:40:14.119155Z","shell.execute_reply":"2025-03-05T19:40:14.119041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}