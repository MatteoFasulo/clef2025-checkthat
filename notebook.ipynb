{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10881030,"sourceType":"datasetVersion","datasetId":6742324,"isSourceIdPinned":false}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Subjectivity in News Articles\n\n## Group:\n- Luca Babboni - luca.babboni2@studio.unibo.it\n- Matteo Fasulo - matteo.fasulo@studio.unibo.it\n- Luca Tedeschini - luca.tedeschini3@studio.unibo.it\n\n## Description\n\nThis notebook addresses Task 1 proposed in [CheckThat Lab](https://checkthat.gitlab.io/clef2025/) of CLEF 2025. In this task, systems are challenged to distinguish whether a sentence from a news article expresses the subjective view of the author behind it or presents an objective view on the covered topic instead.\n\nThis is a binary classification tasks in which systems have to identify whether a text sequence (a sentence or a paragraph) is subjective (SUBJ) or objective (OBJ).\n\nThe task comprises three settings:\n\n* Monolingual: train and test on data in a given language\n* Multilingual: train and test on data comprising several languages\n* Zero-shot: train on several languages and test on unseen languages\n\ntraining data in five languages:\n* Arabic\n* Bulgarian\n* English\n* German\n* Italian\n\nThe official evaluation is macro-averaged F1 between the two classes.","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install -U transformers[torch] bitsandbytes trl peft","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.kill(os.getpid(), 9)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nimport os\nimport gc\nfrom pathlib import Path\n\nimport csv\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\n\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nfrom sentence_transformers import SentenceTransformer\nfrom datasets import Dataset\nfrom huggingface_hub import notebook_login\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    Trainer, \n    TrainingArguments, \n    DataCollatorWithPadding, \n    BitsAndBytesConfig,\n    pipeline, \n    get_linear_schedule_with_warmup\n)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T16:05:04.985011Z","iopub.execute_input":"2025-03-05T16:05:04.985490Z","iopub.status.idle":"2025-03-05T16:05:05.000191Z","shell.execute_reply.started":"2025-03-05T16:05:04.985453Z","shell.execute_reply":"2025-03-05T16:05:04.999171Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"SEED = 42\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T16:05:05.001193Z","iopub.execute_input":"2025-03-05T16:05:05.001518Z","iopub.status.idle":"2025-03-05T16:05:05.018963Z","shell.execute_reply.started":"2025-03-05T16:05:05.001486Z","shell.execute_reply":"2025-03-05T16:05:05.018067Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"np.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T16:05:05.019938Z","iopub.execute_input":"2025-03-05T16:05:05.020246Z","iopub.status.idle":"2025-03-05T16:05:05.035581Z","shell.execute_reply.started":"2025-03-05T16:05:05.020223Z","shell.execute_reply":"2025-03-05T16:05:05.034729Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Subjectivity:\n    def __init__(self, data_folder: str = 'data', seed: int = 42, device: str = 'cuda'):\n        self.seed = seed\n        self.device = device\n        self.languages = [language for language in os.listdir(data_folder)]\n\n        dataset = self.create_dataset(data_folder=data_folder)\n        self.dataset = dataset\n        \n        train, dev, test = self.get_splits(dataset, print_shapes=True)\n        self.train = train\n        self.dev = dev\n        self.test = test\n\n        self.all_data = self.get_per_lang_dataset()\n        \n\n    def create_dataset(self, data_folder: str = 'data'):\n        dataset = pd.DataFrame(columns=['sentence_id','sentence','label','lang','split'])\n        for language in os.listdir(data_folder):\n            for filename in os.listdir(f\"{data_folder}{os.sep}{language}\"):\n                if '.tsv' in filename:\n                    abs_path = f\"{data_folder}{os.sep}{language}{os.sep}{filename}\"\n                    df = pd.read_csv(abs_path, sep='\\t', quoting=csv.QUOTE_NONE)\n                    if 'solved_conflict' in df.columns:\n                        df.drop(columns=['solved_conflict'], inplace=True)\n                    df['lang'] = language\n                    df['split'] = Path(filename).stem\n                    dataset = pd.concat([dataset, df], axis=0)\n        return dataset\n\n    def get_splits(self, dataset: pd.DataFrame, print_shapes: bool = True):\n        train = dataset[dataset['split'].str.contains('train')].copy()\n        dev = dataset[(dataset['split'].str.contains('dev')) & ~(dataset['split'].str.contains('dev_test'))].copy()\n        test = dataset[dataset['split'].str.contains('dev_test')].copy()\n\n        # encode the target variable to int (0: obj; 1: subj)\n        train.loc[:, 'label'] = train['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n        dev.loc[:, 'label'] = dev['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n        test.loc[:, 'label'] = test['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n\n        # cast to int\n        train['label'] = train['label'].astype(int)\n        dev['label'] = dev['label'].astype(int)\n        test['label'] = test['label'].astype(int)\n\n        if print_shapes:\n            print(f\"Train: {train.shape}\")\n            print(f\"Dev: {dev.shape}\")\n            print(f\"Test: {test.shape}\")\n            \n        return train, dev, test\n\n    def get_per_lang_dataset(self):\n        \"\"\"\n        dataset_dict = {\n            'english': {\n                'train': ...\n                'dev': ...\n                'test': ...\n            },\n        }\n        \"\"\"\n        dataset_dict = {}\n        for language in self.languages:\n            dataset_dict[language] = {}\n            # get the train data\n            dataset_dict[language]['train'] = self.train[self.train['lang']==language].copy()\n            # get the dev data\n            dataset_dict[language]['dev'] = self.dev[self.dev['lang']==language].copy()\n            # get the test data\n            dataset_dict[language]['test'] = self.test[self.test['lang']==language].copy()\n        return dataset_dict\n\n    def print_label_distrib(self, dataset: pd.DataFrame):\n        print(dataset['label'].value_counts(normalize=True))\n\n    def get_baseline_model(self, model_name: str = \"paraphrase-multilingual-MiniLM-L12-v2\"):\n        vect = SentenceTransformer(model_name)\n        self.vect = vect\n        return vect\n\n    def train_baseline_model(self, vect, train_data: pd.DataFrame, test_data: pd.DataFrame, solver: str = 'saga'):\n        model = LogisticRegression(class_weight=\"balanced\", solver=solver, random_state=self.seed)\n        model.fit(X=vect.encode(train_data['sentence'].values), y=train_data['label'].values)\n        predictions = model.predict(X=vect.encode(test_data['sentence'].values)).tolist()\n\n        # eval performances\n        perfs = self.evaluate_model(gold_values=test_data['label'].values, predicted_values=predictions)\n\n        return perfs\n\n    def get_tokenizer(self, model_card: str = \"microsoft/mdeberta-v3-base\"):\n        tokenizer = AutoTokenizer.from_pretrained(model_card)\n        self.tokenizer = tokenizer\n        return tokenizer\n\n    def get_model(self, model_card: str = \"microsoft/mdeberta-v3-base\", *args, **kwargs):\n        model = AutoModelForSequenceClassification.from_pretrained(model_card, *args, **kwargs)\n        self.model = model\n        return model\n\n    def get_class_weights(self, dataset: pd.DataFrame):\n        class_weights = compute_class_weight('balanced', classes=np.unique(dataset['label']), y=dataset['label'])\n        return class_weights\n\n    def evaluate_model(self, gold_values, predicted_values):\n        acc = accuracy_score(gold_values, predicted_values)\n        m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(gold_values, predicted_values, average=\"macro\",\n                                                                   zero_division=0)\n        p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(gold_values, predicted_values, labels=[1],\n                                                                   zero_division=0)\n    \n        return {\n            'macro_F1': m_f1,\n            'macro_P': m_prec,\n            'macro_R': m_rec,\n            'SUBJ_F1': p_f1[0],\n            'SUBJ_P': p_prec[0],\n            'SUBJ_R': p_rec[0],\n            'accuracy': acc\n        }","metadata":{"execution":{"iopub.status.busy":"2025-03-05T16:05:05.036776Z","iopub.execute_input":"2025-03-05T16:05:05.037099Z","iopub.status.idle":"2025-03-05T16:05:05.055621Z","shell.execute_reply.started":"2025-03-05T16:05:05.037069Z","shell.execute_reply":"2025-03-05T16:05:05.054632Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data_folder = '/kaggle/input/clef2025-checkthat/data' # data","metadata":{"execution":{"iopub.status.busy":"2025-03-05T16:05:05.056700Z","iopub.execute_input":"2025-03-05T16:05:05.057098Z","iopub.status.idle":"2025-03-05T16:05:05.075056Z","shell.execute_reply.started":"2025-03-05T16:05:05.057074Z","shell.execute_reply":"2025-03-05T16:05:05.074130Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"detector = Subjectivity(data_folder=data_folder, seed=SEED, device=device)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T16:05:05.075893Z","iopub.execute_input":"2025-03-05T16:05:05.076193Z","iopub.status.idle":"2025-03-05T16:05:05.269082Z","shell.execute_reply.started":"2025-03-05T16:05:05.076164Z","shell.execute_reply":"2025-03-05T16:05:05.268141Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: (6418, 5)\nDev: (2401, 5)\nTest: (2332, 5)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"detector.print_label_distrib(detector.train)\ndetector.print_label_distrib(detector.dev)\ndetector.print_label_distrib(detector.test)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T16:05:05.271533Z","iopub.execute_input":"2025-03-05T16:05:05.271823Z","iopub.status.idle":"2025-03-05T16:05:05.280478Z","shell.execute_reply.started":"2025-03-05T16:05:05.271801Z","shell.execute_reply":"2025-03-05T16:05:05.279767Z"},"trusted":true},"outputs":[{"name":"stdout","text":"label\n0    0.631349\n1    0.368651\nName: proportion, dtype: float64\nlabel\n0    0.612245\n1    0.387755\nName: proportion, dtype: float64\nlabel\n0    0.657376\n1    0.342624\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"notebook_login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = {}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model (English)","metadata":{}},{"cell_type":"code","source":"vect = detector.get_baseline_model(model_name=\"paraphrase-multilingual-MiniLM-L12-v2\")\nvect","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.all_data['english']['train'], detector.all_data['english']['test'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model (italian)","metadata":{}},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.all_data['italian']['train'], detector.all_data['italian']['test'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model (multilingual)","metadata":{}},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.train, detector.test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (Arabic)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L3700 (with some minor changes removing useless parts)\nclass CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Ensure label_weights is a tensor\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n        else:\n            self.class_weights = None\n\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        # Extract labels and convert them to long type for cross_entropy\n        labels = inputs.pop(\"labels\").long()\n\n        # Forward pass\n        outputs = model(**inputs)\n\n        # Extract logits assuming they are directly outputted by the model\n        logits = outputs.get('logits')\n\n        # Compute custom loss with class weights for imbalanced data handling\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:05:05.284154Z","iopub.execute_input":"2025-03-05T16:05:05.284470Z","iopub.status.idle":"2025-03-05T16:05:05.296759Z","shell.execute_reply.started":"2025-03-05T16:05:05.284439Z","shell.execute_reply":"2025-03-05T16:05:05.295816Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def tokenize_text(texts):\n    return tokenizer(texts['sentence'], padding=True, truncation=True, max_length=256, return_tensors='pt')\n\ndef evaluate_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    acc = accuracy_score(labels, predictions)\n    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                                zero_division=0)\n    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                                zero_division=0)\n\n    return {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:05:05.297793Z","iopub.execute_input":"2025-03-05T16:05:05.298021Z","iopub.status.idle":"2025-03-05T16:05:05.316937Z","shell.execute_reply.started":"2025-03-05T16:05:05.298001Z","shell.execute_reply":"2025-03-05T16:05:05.315957Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"language = 'arabic'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (Bulgarian)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'bulgarian'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (German)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'german'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (italian)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'italian'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (multilingual)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.train)\ndev_data = Dataset.from_pandas(detector.dev)\ntest_data = Dataset.from_pandas(detector.test)\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-multilingual\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults['multi'] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix (multilingual)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(results).T.sort_values(by='macro_F1', ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# ModernBERT-base (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:16:50.170419Z","iopub.execute_input":"2025-03-05T16:16:50.170899Z","iopub.status.idle":"2025-03-05T16:16:50.779648Z","shell.execute_reply.started":"2025-03-05T16:16:50.170856Z","shell.execute_reply":"2025-03-05T16:16:50.778714Z"}},"outputs":[{"name":"stdout","text":"Model deleted!\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"38"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"model_card = \"answerdotai/ModernBERT-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:16:50.780912Z","iopub.execute_input":"2025-03-05T16:16:50.781271Z","iopub.status.idle":"2025-03-05T16:16:55.535668Z","shell.execute_reply.started":"2025-03-05T16:16:50.781238Z","shell.execute_reply":"2025-03-05T16:16:55.534957Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df789d94e9da4ba6beebaf939504f160"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3f225ffa1840d19130208b912d4e23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b4a166e4c0241d3975ed3ea2cd4bf77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cc10707c6984f70b1baa480067e3b1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5678ef93a91842388720cc5961d90878"}},"metadata":{}},{"name":"stderr","text":"Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:17:00.340527Z","iopub.execute_input":"2025-03-05T16:17:00.340902Z","iopub.status.idle":"2025-03-05T16:17:00.786949Z","shell.execute_reply.started":"2025-03-05T16:17:00.340869Z","shell.execute_reply":"2025-03-05T16:17:00.786103Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/830 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d0f5d62beb40dc80f69b654cc0778f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/462 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78758da435ad43caa9559ac0983db574"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ef128cfcdee4240b21e719de72705af"}},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"ModernBERT-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:17:04.705488Z","iopub.execute_input":"2025-03-05T16:17:04.705858Z","iopub.status.idle":"2025-03-05T16:17:04.739279Z","shell.execute_reply.started":"2025-03-05T16:17:04.705823Z","shell.execute_reply":"2025-03-05T16:17:04.738593Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:13:44.036969Z","iopub.execute_input":"2025-03-05T16:13:44.037279Z","iopub.status.idle":"2025-03-05T16:13:44.051183Z","shell.execute_reply.started":"2025-03-05T16:13:44.037256Z","shell.execute_reply":"2025-03-05T16:13:44.050428Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults['english-modern-bert'] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix (english-modern-bert)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:16:43.473935Z","iopub.status.idle":"2025-03-05T16:16:43.474190Z","shell.execute_reply":"2025-03-05T16:16:43.474089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(results).T.sort_values(by='macro_F1', ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Llama-3.2-1B (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"meta-llama/Llama-3.2-1B\" # meta-llama/Meta-Llama-3-8B","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit = False, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_card, add_prefix_space=True)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card,\n    quantization_config=quantization_config,\n    num_labels=2,\n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'arabic'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-4\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=\"Llama-3.2-1B-subjectivity\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions, labels, _ = trainer.predict(test_data)\nevaluate_metrics((predictions, labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}