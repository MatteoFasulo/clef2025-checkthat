{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10881030,"sourceType":"datasetVersion","datasetId":6742324,"isSourceIdPinned":false}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Subjectivity in News Articles\n\n## Group:\n- Luca Babboni - luca.babboni2@studio.unibo.it\n- Matteo Fasulo - matteo.fasulo@studio.unibo.it\n- Luca Tedeschini - luca.tedeschini3@studio.unibo.it\n\n## Description\n\nThis notebook addresses Task 1 proposed in [CheckThat Lab](https://checkthat.gitlab.io/clef2025/) of CLEF 2025. In this task, systems are challenged to distinguish whether a sentence from a news article expresses the subjective view of the author behind it or presents an objective view on the covered topic instead.\n\nThis is a binary classification tasks in which systems have to identify whether a text sequence (a sentence or a paragraph) is subjective (SUBJ) or objective (OBJ).\n\nThe task comprises three settings:\n\n* Monolingual: train and test on data in a given language\n* Multilingual: train and test on data comprising several languages\n* Zero-shot: train on several languages and test on unseen languages\n\ntraining data in five languages:\n* Arabic\n* Bulgarian\n* English\n* German\n* Italian\n\nThe official evaluation is macro-averaged F1 between the two classes.","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install -U transformers[torch] bitsandbytes trl peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:44:30.385302Z","iopub.execute_input":"2025-03-05T17:44:30.385565Z","execution_failed":"2025-03-05T17:44:48.479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.kill(os.getpid(), 9)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-05T17:44:48.479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nimport os\nimport gc\nfrom pathlib import Path\n\nimport csv\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\n\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nfrom sentence_transformers import SentenceTransformer\nfrom datasets import Dataset\nfrom huggingface_hub import notebook_login\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    Trainer, \n    TrainingArguments, \n    DataCollatorWithPadding, \n    BitsAndBytesConfig,\n    pipeline, \n    get_linear_schedule_with_warmup\n)","metadata":{"execution":{"execution_failed":"2025-03-05T17:44:48.480Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 42\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-05T17:42:26.535960Z","iopub.execute_input":"2025-03-05T17:42:26.536245Z","iopub.status.idle":"2025-03-05T17:42:26.553172Z","shell.execute_reply.started":"2025-03-05T17:42:26.536217Z","shell.execute_reply":"2025-03-05T17:42:26.552387Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"np.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T17:42:26.553894Z","iopub.execute_input":"2025-03-05T17:42:26.554110Z","iopub.status.idle":"2025-03-05T17:42:26.567600Z","shell.execute_reply.started":"2025-03-05T17:42:26.554092Z","shell.execute_reply":"2025-03-05T17:42:26.566982Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Subjectivity:\n    def __init__(self, data_folder: str = 'data', seed: int = 42, device: str = 'cuda'):\n        self.seed = seed\n        self.device = device\n        self.languages = [language for language in os.listdir(data_folder)]\n\n        dataset = self.create_dataset(data_folder=data_folder)\n        self.dataset = dataset\n        \n        train, dev, test = self.get_splits(dataset, print_shapes=True)\n        self.train = train\n        self.dev = dev\n        self.test = test\n\n        self.all_data = self.get_per_lang_dataset()\n        \n\n    def create_dataset(self, data_folder: str = 'data'):\n        dataset = pd.DataFrame(columns=['sentence_id','sentence','label','lang','split'])\n        for language in os.listdir(data_folder):\n            for filename in os.listdir(f\"{data_folder}{os.sep}{language}\"):\n                if '.tsv' in filename:\n                    abs_path = f\"{data_folder}{os.sep}{language}{os.sep}{filename}\"\n                    df = pd.read_csv(abs_path, sep='\\t', quoting=csv.QUOTE_NONE)\n                    if 'solved_conflict' in df.columns:\n                        df.drop(columns=['solved_conflict'], inplace=True)\n                    df['lang'] = language\n                    df['split'] = Path(filename).stem\n                    dataset = pd.concat([dataset, df], axis=0)\n        return dataset\n\n    def get_splits(self, dataset: pd.DataFrame, print_shapes: bool = True):\n        train = dataset[dataset['split'].str.contains('train')].copy()\n        dev = dataset[(dataset['split'].str.contains('dev')) & ~(dataset['split'].str.contains('dev_test'))].copy()\n        test = dataset[dataset['split'].str.contains('dev_test')].copy()\n\n        # encode the target variable to int (0: obj; 1: subj)\n        train.loc[:, 'label'] = train['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n        dev.loc[:, 'label'] = dev['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n        test.loc[:, 'label'] = test['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n\n        # cast to int\n        train['label'] = train['label'].astype(int)\n        dev['label'] = dev['label'].astype(int)\n        test['label'] = test['label'].astype(int)\n\n        if print_shapes:\n            print(f\"Train: {train.shape}\")\n            print(f\"Dev: {dev.shape}\")\n            print(f\"Test: {test.shape}\")\n            \n        return train, dev, test\n\n    def get_per_lang_dataset(self):\n        \"\"\"\n        dataset_dict = {\n            'english': {\n                'train': ...\n                'dev': ...\n                'test': ...\n            },\n        }\n        \"\"\"\n        dataset_dict = {}\n        for language in self.languages:\n            dataset_dict[language] = {}\n            # get the train data\n            dataset_dict[language]['train'] = self.train[self.train['lang']==language].copy()\n            # get the dev data\n            dataset_dict[language]['dev'] = self.dev[self.dev['lang']==language].copy()\n            # get the test data\n            dataset_dict[language]['test'] = self.test[self.test['lang']==language].copy()\n        return dataset_dict\n\n    def print_label_distrib(self, dataset: pd.DataFrame):\n        print(dataset['label'].value_counts(normalize=True))\n\n    def get_baseline_model(self, model_name: str = \"paraphrase-multilingual-MiniLM-L12-v2\"):\n        vect = SentenceTransformer(model_name)\n        self.vect = vect\n        return vect\n\n    def train_baseline_model(self, vect, train_data: pd.DataFrame, test_data: pd.DataFrame, solver: str = 'saga'):\n        model = LogisticRegression(class_weight=\"balanced\", solver=solver, random_state=self.seed)\n        model.fit(X=vect.encode(train_data['sentence'].values), y=train_data['label'].values)\n        predictions = model.predict(X=vect.encode(test_data['sentence'].values)).tolist()\n\n        # eval performances\n        perfs = self.evaluate_model(gold_values=test_data['label'].values, predicted_values=predictions)\n\n        return perfs\n\n    def get_tokenizer(self, model_card: str = \"microsoft/mdeberta-v3-base\"):\n        tokenizer = AutoTokenizer.from_pretrained(model_card)\n        self.tokenizer = tokenizer\n        return tokenizer\n\n    def get_model(self, model_card: str = \"microsoft/mdeberta-v3-base\", *args, **kwargs):\n        model = AutoModelForSequenceClassification.from_pretrained(model_card, *args, **kwargs)\n        self.model = model\n        return model\n\n    def get_class_weights(self, dataset: pd.DataFrame):\n        class_weights = compute_class_weight('balanced', classes=np.unique(dataset['label']), y=dataset['label'])\n        return class_weights\n\n    def evaluate_model(self, gold_values, predicted_values):\n        acc = accuracy_score(gold_values, predicted_values)\n        m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(gold_values, predicted_values, average=\"macro\",\n                                                                   zero_division=0)\n        p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(gold_values, predicted_values, labels=[1],\n                                                                   zero_division=0)\n    \n        return {\n            'macro_F1': m_f1,\n            'macro_P': m_prec,\n            'macro_R': m_rec,\n            'SUBJ_F1': p_f1[0],\n            'SUBJ_P': p_prec[0],\n            'SUBJ_R': p_rec[0],\n            'accuracy': acc\n        }","metadata":{"execution":{"iopub.status.busy":"2025-03-05T17:42:26.568589Z","iopub.execute_input":"2025-03-05T17:42:26.568893Z","iopub.status.idle":"2025-03-05T17:42:26.585145Z","shell.execute_reply.started":"2025-03-05T17:42:26.568864Z","shell.execute_reply":"2025-03-05T17:42:26.584532Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"data_folder = '/kaggle/input/clef2025-checkthat/data' # data","metadata":{"execution":{"iopub.status.busy":"2025-03-05T17:42:26.589298Z","iopub.execute_input":"2025-03-05T17:42:26.589562Z","iopub.status.idle":"2025-03-05T17:42:26.603251Z","shell.execute_reply.started":"2025-03-05T17:42:26.589529Z","shell.execute_reply":"2025-03-05T17:42:26.602294Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"detector = Subjectivity(data_folder=data_folder, seed=SEED, device=device)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T17:42:26.603986Z","iopub.execute_input":"2025-03-05T17:42:26.604192Z","iopub.status.idle":"2025-03-05T17:42:26.797547Z","shell.execute_reply.started":"2025-03-05T17:42:26.604174Z","shell.execute_reply":"2025-03-05T17:42:26.796619Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: (6418, 5)\nDev: (2401, 5)\nTest: (2332, 5)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"detector.print_label_distrib(detector.train)\ndetector.print_label_distrib(detector.dev)\ndetector.print_label_distrib(detector.test)","metadata":{"execution":{"iopub.status.busy":"2025-03-05T17:42:26.798503Z","iopub.execute_input":"2025-03-05T17:42:26.798854Z","iopub.status.idle":"2025-03-05T17:42:26.808100Z","shell.execute_reply.started":"2025-03-05T17:42:26.798829Z","shell.execute_reply":"2025-03-05T17:42:26.807104Z"},"trusted":true},"outputs":[{"name":"stdout","text":"label\n0    0.631349\n1    0.368651\nName: proportion, dtype: float64\nlabel\n0    0.612245\n1    0.387755\nName: proportion, dtype: float64\nlabel\n0    0.657376\n1    0.342624\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"notebook_login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = {}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L3700 (with some minor changes removing useless parts)\nclass CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, weights_dtype=torch.float32, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Ensure label_weights is a tensor\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, dtype=weights_dtype).to(self.args.device)\n        else:\n            self.class_weights = None\n\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        # Extract labels and convert them to long type for cross_entropy\n        labels = inputs.pop(\"labels\").long()\n\n        # Forward pass\n        outputs = model(**inputs)\n\n        # Extract logits assuming they are directly outputted by the model\n        logits = outputs.get('logits')\n\n        # Compute custom loss with class weights for imbalanced data handling\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss\n\ndef tokenize_text(texts):\n    return tokenizer(texts['sentence'], padding=True, truncation=True, max_length=256, return_tensors='pt')\n\ndef evaluate_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    acc = accuracy_score(labels, predictions)\n    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                                zero_division=0)\n    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                                zero_division=0)\n\n    return {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:26.808972Z","iopub.execute_input":"2025-03-05T17:42:26.809204Z","iopub.status.idle":"2025-03-05T17:42:26.821232Z","shell.execute_reply.started":"2025-03-05T17:42:26.809184Z","shell.execute_reply":"2025-03-05T17:42:26.820518Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Baseline Model (English)","metadata":{}},{"cell_type":"code","source":"vect = detector.get_baseline_model(model_name=\"paraphrase-multilingual-MiniLM-L12-v2\")\nvect","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.all_data['english']['train'], detector.all_data['english']['test'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model (italian)","metadata":{}},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.all_data['italian']['train'], detector.all_data['italian']['test'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model (multilingual)","metadata":{}},{"cell_type":"code","source":"detector.train_baseline_model(vect, detector.train, detector.test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (Arabic)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'arabic'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (Bulgarian)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'bulgarian'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (German)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'german'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (italian)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'italian'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults[language] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (multilingual)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = detector.get_model(\n    model_card=model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.train)\ndev_data = Dataset.from_pandas(detector.dev)\ntest_data = Dataset.from_pandas(detector.test)\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-multilingual\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults['multi'] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix (multilingual)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(results).T.sort_values(by='macro_F1', ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# ModernBERT-base (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"answerdotai/ModernBERT-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"ModernBERT-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_labels, _ = trainer.predict(test_data)\n\nstats = evaluate_metrics((test_predictions, test_labels))\n\ntest_predictions = np.argmax(test_predictions, axis=1)\n\nprint(stats)\nresults['english-modern-bert'] = stats\n\ntrainer.push_to_hub()\n\ncm = confusion_matrix(test_labels, test_predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix (english-modern-bert)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(results).T.sort_values(by='macro_F1', ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Llama-3.2-1B (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"meta-llama/Llama-3.2-1B\" # meta-llama/Meta-Llama-3-8B","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit = False, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_card, add_prefix_space=True)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card,\n    quantization_config=quantization_config,\n    num_labels=2,\n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-4\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=\"Llama-3.2-1B-subjectivity-english\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions, labels, _ = trainer.predict(test_data)\nevaluate_metrics((predictions, labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Deepseek-llm-7b-base","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:30.120114Z","iopub.execute_input":"2025-03-05T17:42:30.120475Z","iopub.status.idle":"2025-03-05T17:42:30.435398Z","shell.execute_reply.started":"2025-03-05T17:42:30.120431Z","shell.execute_reply":"2025-03-05T17:42:30.434516Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"90"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"model_card = \"deepseek-ai/deepseek-llm-7b-base\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:30.497461Z","iopub.execute_input":"2025-03-05T17:42:30.497760Z","iopub.status.idle":"2025-03-05T17:42:30.501264Z","shell.execute_reply.started":"2025-03-05T17:42:30.497736Z","shell.execute_reply":"2025-03-05T17:42:30.500402Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit = True, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\nlora_config = LoraConfig(\n    r = 8, # the dimension of the low-rank matrices\n    lora_alpha = 32, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:30.832012Z","iopub.execute_input":"2025-03-05T17:42:30.832342Z","iopub.status.idle":"2025-03-05T17:42:30.838039Z","shell.execute_reply.started":"2025-03-05T17:42:30.832286Z","shell.execute_reply":"2025-03-05T17:42:30.837400Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_card)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card,\n    quantization_config=quantization_config,\n    num_labels=2,\n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:32.104779Z","iopub.execute_input":"2025-03-05T17:42:32.105072Z","iopub.status.idle":"2025-03-05T17:42:46.982162Z","shell.execute_reply.started":"2025-03-05T17:42:32.105053Z","shell.execute_reply":"2025-03-05T17:42:46.981355Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0bf6952bcc84f128b85876060f794dc"}},"metadata":{}},{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/deepseek-llm-7b-base and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:46.983616Z","iopub.execute_input":"2025-03-05T17:42:46.983990Z","iopub.status.idle":"2025-03-05T17:42:47.253235Z","shell.execute_reply.started":"2025-03-05T17:42:46.983954Z","shell.execute_reply":"2025-03-05T17:42:47.252441Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): LlamaForSequenceClassification(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(102400, 4096)\n        (layers): ModuleList(\n          (0-29): 30 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-06)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (score): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=4096, out_features=2, bias=False)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=4096, out_features=2, bias=False)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:47.255286Z","iopub.execute_input":"2025-03-05T17:42:47.255573Z","iopub.status.idle":"2025-03-05T17:42:47.259956Z","shell.execute_reply.started":"2025-03-05T17:42:47.255550Z","shell.execute_reply":"2025-03-05T17:42:47.258734Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 4\nlr = 1e-4\nweight_decay = 0.1\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:47.261255Z","iopub.execute_input":"2025-03-05T17:42:47.261577Z","iopub.status.idle":"2025-03-05T17:42:47.833803Z","shell.execute_reply.started":"2025-03-05T17:42:47.261554Z","shell.execute_reply":"2025-03-05T17:42:47.832737Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/830 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2220b704a08d451cb13a39173543eecc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/462 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab9b91e933e43cab039f66f6a615411"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7679b7f6330346c69ecc4330a06509c9"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=\"deepseek-llm-7b-base-subjectivity-english\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    #gradient_accumulation_steps=16,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_F1\",\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:47.834677Z","iopub.execute_input":"2025-03-05T17:42:47.835030Z","iopub.status.idle":"2025-03-05T17:42:47.863362Z","shell.execute_reply.started":"2025-03-05T17:42:47.834994Z","shell.execute_reply":"2025-03-05T17:42:47.862658Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n    weights_dtype=torch.float16,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:42:47.864179Z","execution_failed":"2025-03-05T17:44:04.372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-05T17:44:04.373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions, labels, _ = trainer.predict(test_data)\nevaluate_metrics((predictions, labels))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-05T17:44:04.373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}