{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10881030,"sourceType":"datasetVersion","datasetId":6742324,"isSourceIdPinned":false}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Subjectivity in News Articles\n\n## Group:\n- Luca Babboni - luca.babboni2@studio.unibo.it\n- Matteo Fasulo - matteo.fasulo@studio.unibo.it\n- Luca Tedeschini - luca.tedeschini3@studio.unibo.it\n\n## Description\n\nThis notebook addresses Task 1 proposed in [CheckThat Lab](https://checkthat.gitlab.io/clef2025/) of CLEF 2025. In this task, systems are challenged to distinguish whether a sentence from a news article expresses the subjective view of the author behind it or presents an objective view on the covered topic instead.\n\nThis is a binary classification tasks in which systems have to identify whether a text sequence (a sentence or a paragraph) is subjective (SUBJ) or objective (OBJ).\n\nThe task comprises three settings:\n\n* Monolingual: train and test on data in a given language\n* Multilingual: train and test on data comprising several languages\n* Zero-shot: train on several languages and test on unseen languages\n\ntraining data in five languages:\n* Arabic\n* Bulgarian\n* English\n* German\n* Italian\n\nThe official evaluation is macro-averaged F1 between the two classes.","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nfrom pathlib import Path\n\nimport csv\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom joblib import delayed, Parallel\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\n\nfrom sentence_transformers import SentenceTransformer\nfrom datasets import Dataset\nfrom huggingface_hub import notebook_login\nfrom transformers.modeling_outputs import SequenceClassifierOutput\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, RobertaTokenizerFast, RobertaForSequenceClassification, pipeline","metadata":{"execution":{"iopub.status.busy":"2025-02-28T16:58:43.638271Z","iopub.execute_input":"2025-02-28T16:58:43.638611Z","iopub.status.idle":"2025-02-28T16:58:43.643973Z","shell.execute_reply.started":"2025-02-28T16:58:43.638586Z","shell.execute_reply":"2025-02-28T16:58:43.643145Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"SEED = 42\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-02-28T16:57:56.816335Z","iopub.execute_input":"2025-02-28T16:57:56.816621Z","iopub.status.idle":"2025-02-28T16:57:56.863163Z","shell.execute_reply.started":"2025-02-28T16:57:56.816590Z","shell.execute_reply":"2025-02-28T16:57:56.862283Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data_folder = '/kaggle/input/clef2025-checkthat/data' # /kaggle/input/clef2025-checkthat/data\ndataset = pd.DataFrame(columns=['sentence_id','sentence','label','lang','split'])\n\nfor language in os.listdir(data_folder):\n    for filename in os.listdir(f\"{data_folder}{os.sep}{language}\"):\n        if '.tsv' in filename:\n            abs_path = f\"{data_folder}{os.sep}{language}{os.sep}{filename}\"\n            df = pd.read_csv(abs_path, sep='\\t', quoting=csv.QUOTE_NONE)\n            if 'solved_conflict' in df.columns:\n                df.drop(columns=['solved_conflict'], inplace=True)\n            df['lang'] = language\n            df['split'] = Path(filename).stem\n            dataset = pd.concat([dataset, df], axis=0)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T16:57:56.864140Z","iopub.execute_input":"2025-02-28T16:57:56.864528Z","iopub.status.idle":"2025-02-28T16:57:56.999265Z","shell.execute_reply.started":"2025-02-28T16:57:56.864489Z","shell.execute_reply":"2025-02-28T16:57:56.998556Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train = dataset[dataset['split'].str.contains('train')].copy()\ndev = dataset[dataset['split'].str.contains('dev')].copy()\ntest = dataset[dataset['split'].str.contains('dev_test')].copy()\n\nprint(f\"Train: {train.shape}\")\nprint(f\"Dev: {dev.shape}\")\nprint(f\"Test: {test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:57:57.000109Z","iopub.execute_input":"2025-02-28T16:57:57.000417Z","iopub.status.idle":"2025-02-28T16:57:57.021451Z","shell.execute_reply.started":"2025-02-28T16:57:57.000390Z","shell.execute_reply":"2025-02-28T16:57:57.020660Z"}},"outputs":[{"name":"stdout","text":"Train: (6418, 5)\nDev: (4733, 5)\nTest: (2332, 5)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(f\"Train: {train['label'].value_counts(normalize=True)}\")\nprint(f\"Dev: {dev['label'].value_counts(normalize=True)}\")\nprint(f\"Test: {test['label'].value_counts(normalize=True)}\")","metadata":{"execution":{"iopub.status.busy":"2025-02-28T16:57:57.022409Z","iopub.execute_input":"2025-02-28T16:57:57.022677Z","iopub.status.idle":"2025-02-28T16:57:57.032441Z","shell.execute_reply.started":"2025-02-28T16:57:57.022655Z","shell.execute_reply":"2025-02-28T16:57:57.031678Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: label\nOBJ     0.631349\nSUBJ    0.368651\nName: proportion, dtype: float64\nDev: label\nOBJ     0.634481\nSUBJ    0.365519\nName: proportion, dtype: float64\nTest: label\nOBJ     0.657376\nSUBJ    0.342624\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Legend:\n* Objective -> 0\n* Subjective -> 1","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'label'] = train['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\ndev.loc[:, 'label'] = dev['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\ntest.loc[:, 'label'] = test['label'].apply(lambda x: 0 if x == 'OBJ' else 1)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T16:57:57.034297Z","iopub.execute_input":"2025-02-28T16:57:57.034647Z","iopub.status.idle":"2025-02-28T16:57:57.055275Z","shell.execute_reply.started":"2025-02-28T16:57:57.034607Z","shell.execute_reply":"2025-02-28T16:57:57.054494Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train['label'] = train['label'].astype(int)\ndev['label'] = dev['label'].astype(int)\ntest['label'] = test['label'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:57:57.056111Z","iopub.execute_input":"2025-02-28T16:57:57.056356Z","iopub.status.idle":"2025-02-28T16:57:57.072463Z","shell.execute_reply.started":"2025-02-28T16:57:57.056323Z","shell.execute_reply":"2025-02-28T16:57:57.071705Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#notebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:57:57.075813Z","iopub.execute_input":"2025-02-28T16:57:57.076110Z","iopub.status.idle":"2025-02-28T16:57:57.086952Z","shell.execute_reply.started":"2025-02-28T16:57:57.076088Z","shell.execute_reply":"2025-02-28T16:57:57.086337Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"code","source":"vect = SentenceTransformer(\"all-mpnet-base-v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:57:59.360631Z","iopub.execute_input":"2025-02-28T16:57:59.360984Z","iopub.status.idle":"2025-02-28T16:58:00.391076Z","shell.execute_reply.started":"2025-02-28T16:57:59.360957Z","shell.execute_reply":"2025-02-28T16:58:00.390125Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = LogisticRegression(class_weight=\"balanced\", random_state=SEED)\nmodel.fit(X=vect.encode(train['sentence'].values), y=train['label'].values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:58:00.392369Z","iopub.execute_input":"2025-02-28T16:58:00.392712Z","iopub.status.idle":"2025-02-28T16:58:25.896679Z","shell.execute_reply.started":"2025-02-28T16:58:00.392683Z","shell.execute_reply":"2025-02-28T16:58:25.895670Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e3ffc7467544c09ab8d81e7617d47b7"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(class_weight='balanced', random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"predictions = model.predict(X=vect.encode(test['sentence'].values)).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:58:25.898668Z","iopub.execute_input":"2025-02-28T16:58:25.898925Z","iopub.status.idle":"2025-02-28T16:58:35.438042Z","shell.execute_reply.started":"2025-02-28T16:58:25.898903Z","shell.execute_reply":"2025-02-28T16:58:35.436952Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/73 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abc91514505c473c81e26408a478bd7f"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"pred_df = pd.DataFrame()\npred_df['sentence_id'] = test['sentence_id']\npred_df['label'] = predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:58:35.439181Z","iopub.execute_input":"2025-02-28T16:58:35.439504Z","iopub.status.idle":"2025-02-28T16:58:35.447193Z","shell.execute_reply.started":"2025-02-28T16:58:35.439480Z","shell.execute_reply":"2025-02-28T16:58:35.446193Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def evaluate_model(gold_values, predicted_values):\n    acc = accuracy_score(gold_values, predicted_values)\n    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(gold_values, predicted_values, average=\"macro\",\n                                                               zero_division=0)\n    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(gold_values, predicted_values, labels=[1],\n                                                               zero_division=0)\n    #roc_auc = roc_auc_score(gold_values, predicted_probabilities)\n\n    return {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc,\n        #'roc_auc': roc_auc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:58:35.448310Z","iopub.execute_input":"2025-02-28T16:58:35.448584Z","iopub.status.idle":"2025-02-28T16:58:35.463839Z","shell.execute_reply.started":"2025-02-28T16:58:35.448561Z","shell.execute_reply":"2025-02-28T16:58:35.462987Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"evaluate_model(gold_values=test.label.values, predicted_values=predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T16:58:35.464822Z","iopub.execute_input":"2025-02-28T16:58:35.465197Z","iopub.status.idle":"2025-02-28T16:58:35.495280Z","shell.execute_reply.started":"2025-02-28T16:58:35.465171Z","shell.execute_reply":"2025-02-28T16:58:35.494313Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'macro_F1': 0.5973258985425796,\n 'macro_P': 0.5989696474182998,\n 'macro_R': 0.6083138006003918,\n 'SUBJ_F1': 0.5101258894362343,\n 'SUBJ_P': 0.45330739299610895,\n 'SUBJ_R': 0.5832290362953693,\n 'accuracy': 0.6162092624356775}"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\ndel model\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T17:07:58.567873Z","iopub.execute_input":"2025-02-28T17:07:58.568166Z","iopub.status.idle":"2025-02-28T17:07:58.651404Z","shell.execute_reply.started":"2025-02-28T17:07:58.568144Z","shell.execute_reply":"2025-02-28T17:07:58.650355Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-cd8e5cc0e7a9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":62},{"cell_type":"markdown","source":"# Twitter RoBERTa-base 2022 154M","metadata":{}},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_card, use_Fast=False)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_card, num_labels=2, id2label={0: 'OBJ', 1: 'SUBJ'}, label2id={'OBJ': 0, 'SUBJ': 1})","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:07:59.321788Z","iopub.execute_input":"2025-02-28T17:07:59.322082Z","iopub.status.idle":"2025-02-28T17:08:02.113740Z","shell.execute_reply.started":"2025-02-28T17:07:59.322059Z","shell.execute_reply":"2025-02-28T17:08:02.112778Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"def preprocess_text(texts):\n    return tokenizer(texts['sentence'])","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:02.115846Z","iopub.execute_input":"2025-02-28T17:08:02.116106Z","iopub.status.idle":"2025-02-28T17:08:02.120520Z","shell.execute_reply.started":"2025-02-28T17:08:02.116080Z","shell.execute_reply":"2025-02-28T17:08:02.119835Z"},"trusted":true},"outputs":[],"execution_count":64},{"cell_type":"code","source":"train_dl = Dataset.from_pandas(train)\ndev_dl = Dataset.from_pandas(dev)\ntest_dl = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:02.122015Z","iopub.execute_input":"2025-02-28T17:08:02.122259Z","iopub.status.idle":"2025-02-28T17:08:02.214263Z","shell.execute_reply.started":"2025-02-28T17:08:02.122229Z","shell.execute_reply":"2025-02-28T17:08:02.213555Z"},"trusted":true},"outputs":[],"execution_count":65},{"cell_type":"code","source":"train_dl = train_dl.map(preprocess_text, batched=True)\ndev_dl = dev_dl.map(preprocess_text, batched=True)\ntest_dl = test_dl.map(preprocess_text, batched=True)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:02.215383Z","iopub.execute_input":"2025-02-28T17:08:02.215642Z","iopub.status.idle":"2025-02-28T17:08:03.748036Z","shell.execute_reply.started":"2025-02-28T17:08:02.215609Z","shell.execute_reply":"2025-02-28T17:08:03.747135Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6418 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"139f21132350432982e06898d090af79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4733 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"040d3652abd44e58ad64f09eed9dc85b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2332 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8ff7f8b742746e68e0603cab2ff69c6"}},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:03.749168Z","iopub.execute_input":"2025-02-28T17:08:03.749556Z","iopub.status.idle":"2025-02-28T17:08:03.753467Z","shell.execute_reply.started":"2025-02-28T17:08:03.749513Z","shell.execute_reply":"2025-02-28T17:08:03.752722Z"},"trusted":true},"outputs":[],"execution_count":67},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=f'model',                 \n    learning_rate=6e-5,\n    per_device_train_batch_size=32,         \n    per_device_eval_batch_size=16,\n    #lr_scheduler_type='linear',\n    warmup_steps=400,\n    #label_smoothing_factor=0.1,\n    num_train_epochs=5,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",       \n    save_strategy=\"no\",           \n    #save_safetensors=True,\n    #load_best_model_at_end=True,\n    report_to='none',\n    seed=SEED,\n    data_seed=SEED\n)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:03.754365Z","iopub.execute_input":"2025-02-28T17:08:03.754668Z","iopub.status.idle":"2025-02-28T17:08:03.795408Z","shell.execute_reply.started":"2025-02-28T17:08:03.754638Z","shell.execute_reply":"2025-02-28T17:08:03.794772Z"},"trusted":true},"outputs":[],"execution_count":68},{"cell_type":"code","source":"# Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L3700 (with some minor changes removing useless parts)\nclass CustomTrainer(Trainer):\n    def __init__(self, class_weights, device, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # You pass the class weights when instantiating the Trainer\n        self.class_weights = class_weights\n        self.device = device\n\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        if self.label_smoother is not None and \"labels\" in inputs:\n            labels = inputs.pop(\"labels\")\n        else:\n            labels = None\n        outputs = model(**inputs)\n        if self.args.past_index >= 0:\n            self._past = outputs[self.args.past_index]\n\n        if labels is not None:\n            loss = self.label_smoother(outputs, labels)\n        else:\n            # We extract the logits from the model outputs\n            logits = outputs.get('logits')\n            # We compute the loss manually passing the class weights to the loss function\n            criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(self.device)) # Modified to use the class weights\n            # We compute the loss using the modified criterion\n            loss = criterion(logits, inputs['labels'])\n\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:03.796890Z","iopub.execute_input":"2025-02-28T17:08:03.797103Z","iopub.status.idle":"2025-02-28T17:08:03.803024Z","shell.execute_reply.started":"2025-02-28T17:08:03.797084Z","shell.execute_reply":"2025-02-28T17:08:03.802300Z"},"trusted":true},"outputs":[],"execution_count":69},{"cell_type":"code","source":"class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train['label']), y=train['label'])\nclass_weights = torch.tensor(class_weights, dtype=torch.float32)\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:03.804038Z","iopub.execute_input":"2025-02-28T17:08:03.804278Z","iopub.status.idle":"2025-02-28T17:08:03.825833Z","shell.execute_reply.started":"2025-02-28T17:08:03.804259Z","shell.execute_reply":"2025-02-28T17:08:03.825141Z"},"trusted":true},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"tensor([0.7920, 1.3563])"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"def compute_metrics(output_info):\n    \"\"\"\n    Compute various evaluation metrics for model predictions.\n    \n    Args:\n        output_info (tuple): A tuple containing the model predictions and the true labels.\n            - predictions (np.ndarray): The predicted labels from the model.\n            - labels (np.ndarray): The true labels.\n    \n    Returns:\n        dict: A dictionary containing the computed metrics:\n            - 'f1': The F1 score (macro average).\n            - 'accuracy': The accuracy score.\n            - 'precision': The precision score (macro average).\n            - 'recall': The recall score (macro average).\n    \"\"\"\n    predictions, labels = output_info\n    predictions = np.array(predictions)\n    labels = np.array(labels)\n    predictions = np.argmax(predictions, axis=-1)\n    \n    f1 = f1_score(labels, predictions, average=\"macro\", zero_division=0)\n    acc = accuracy_score(labels, predictions)\n    \n    return {\"f1-score\" : f1, \"Accuracy\" : acc}","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:03.826670Z","iopub.execute_input":"2025-02-28T17:08:03.826982Z","iopub.status.idle":"2025-02-28T17:08:03.841861Z","shell.execute_reply.started":"2025-02-28T17:08:03.826947Z","shell.execute_reply":"2025-02-28T17:08:03.841048Z"},"trusted":true},"outputs":[],"execution_count":71},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dl,\n    eval_dataset=dev_dl,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    class_weights=class_weights,\n    device=device,\n)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:03.842687Z","iopub.execute_input":"2025-02-28T17:08:03.842944Z","iopub.status.idle":"2025-02-28T17:08:04.194284Z","shell.execute_reply.started":"2025-02-28T17:08:03.842925Z","shell.execute_reply":"2025-02-28T17:08:04.193366Z"},"trusted":true},"outputs":[],"execution_count":72},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2025-02-28T17:08:04.195560Z","iopub.execute_input":"2025-02-28T17:08:04.195867Z","execution_failed":"2025-02-28T17:11:55.369Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='317' max='1005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 317/1005 02:40 < 05:49, 1.97 it/s, Epoch 1.57/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1-score</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.559721</td>\n      <td>0.655122</td>\n      <td>0.655187</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"prediction, labels, _ = trainer.predict(test_dl)\nprediction = np.argmax(prediction, axis=1)\ncm = confusion_matrix(y_true=labels, y_pred=prediction, normalize='all')\nprint(roc_auc_score(labels, prediction))\n\nConfusionMatrixDisplay(cm).plot()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T17:07:13.834007Z","iopub.status.idle":"2025-02-28T17:07:13.834325Z","shell.execute_reply":"2025-02-28T17:07:13.834144Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Emotions","metadata":{}},{"cell_type":"code","source":"model_card = \"arpanghoshal/EmoRoBERTa\"\ntokenizer = RobertaTokenizerFast.from_pretrained(model_card)\nmodel = RobertaForSequenceClassification.from_pretrained(model_card, from_tf=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion = pipeline('sentiment-analysis', model='arpanghoshal/EmoRoBERTa', return_all_scores= True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example\nprint(train_data.iloc[0]['sentence'], train_data.iloc[0]['label'])\nemotion_labels = emotion(train_data.iloc[0]['sentence'])\npd.DataFrame(emotion_labels[0]).sort_values(by='score', ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion_array = np.zeros((train_data.shape[0], 28))\n\nfor i, sentence in enumerate(tqdm(train_data['sentence'])):\n    result = emotion(sentence)[0]\n    emotion_array[i] = np.array([list(d.values())[1] for d in result])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion_df_train = pd.DataFrame(emotion_array, columns=[list(d.values())[0] for d in result])\nemotion_df_train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_augmented = pd.concat([train_data, emotion_df_train], axis=1)\ntrain_data_augmented.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion_array = np.zeros((test_data.shape[0], 28))\n\nfor i, sentence in enumerate(tqdm(test_data['sentence'])):\n    result = emotion(sentence)[0]\n    emotion_array[i] = np.array([list(d.values())[1] for d in result])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion_df_test = pd.DataFrame(emotion_array, columns=[list(d.values())[0] for d in result])\nemotion_df_test.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data_augmented = pd.concat([test_data, emotion_df_test], axis=1)\ntest_data_augmented.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not os.path.exists('/kaggle/input/clef2025-checkthat/data/english/train_en_aug.csv'):\n    train_data_augmented.to_csv('train_en_aug.csv', encoding='UTF-8')\n    test_data_augmented.to_csv('dev_test_en_aug.csv', encoding='UTF-8')\nelse:\n    train_data_augmented = pd.read_csv('/kaggle/input/clef2025-checkthat/data/english/train_en_aug.csv', encoding='UTF-8', index_col=0)\n    test_data_augmented = pd.read_csv('/kaggle/input/clef2025-checkthat/data/english/dev_test_en_aug.csv', encoding='UTF-8', index_col=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(text):\n    preprocessed_text = []\n    for t in text.split():\n        if len(t) > 1:\n            t = '@user' if t[0] == '@' and t.count('@') == 1 else t\n            t = 'http' if t.startswith('http') else t\n        preprocessed_text.append(t)\n    return ' '.join(preprocessed_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L3700 (with some minor changes removing useless parts)\nclass CustomTrainer(Trainer):\n    def __init__(self, class_weights, device, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # You pass the class weights when instantiating the Trainer\n        self.class_weights = class_weights\n        self.device = device\n\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        if self.label_smoother is not None and \"labels\" in inputs:\n            labels = inputs.pop(\"labels\")\n        else:\n            labels = None\n        outputs = model(**inputs)\n        if self.args.past_index >= 0:\n            self._past = outputs[self.args.past_index]\n\n        if labels is not None:\n            loss = self.label_smoother(outputs, labels)\n        else:\n            # We extract the logits from the model outputs\n            logits = outputs.logits\n            # We compute the loss manually passing the class weights to the loss function\n            criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(self.device)) # Modified to use the class weights\n            # We compute the loss using the modified criterion\n            loss = criterion(logits, inputs['labels'])\n\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomEmotionModel(nn.Module):\n    def __init__(self, model_card: str, num_labels: int, num_emotions: int, class_weights: torch.Tensor, device):\n        super(CustomEmotionModel, self).__init__()\n        self.base_model = AutoModel.from_pretrained(model_card)\n        #self.emotion_branch = nn.Linear(num_emotions, 128)  # Example: 128 hidden units\n        self.classifier = nn.Linear(self.base_model.config.hidden_size + 28, num_labels)\n        self.class_weights = class_weights.to(device)\n\n    def forward(self, input_ids, attention_mask, emotion_features, labels=None):\n        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n        \n        # Process emotion features\n        #emotion_output = torch.relu(self.emotion_branch(emotion_features))\n        \n        # Concatenate base model output with emotion features\n        combined_output = torch.cat((pooled_output, emotion_features), dim=1)\n        \n        # Apply classification layer\n        logits = self.classifier(combined_output)\n\n        loss = None\n        if labels is not None:\n            criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n            loss = criterion(logits, labels)\n\n        return SequenceClassifierOutput(loss=loss, logits=logits)\n    \n\n\"\"\"Should be something like\n    def forward(self, input_ids, attention_mask, emotion_features, labels=None):\n        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n        \n        # Process emotion features\n        emotion_output = torch.relu(self.emotion_branch(emotion_features))\n        \n        # Concatenate base model output with emotion features\n        combined_output = torch.cat((pooled_output, emotion_output), dim=1)\n        \n        # Apply dropout and classification layer\n        combined_output = self.dropout(combined_output)\n        logits = self.classifier(combined_output)\n\n        loss = None\n        if labels is not None:\n            if self.class_weights is not None:\n                criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n            else:\n                criterion = torch.nn.CrossEntropyLoss()\n            loss = criterion(logits, labels)\n\n        return SequenceClassifierOutput(loss=loss, logits=logits)\n\n    but it doesn't have the class_weight in input so it yields errors\n\"\"\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_augmented['all_emotions'] = train_data_augmented[train_data_augmented.columns[-28:]].apply(lambda x: np.array(x.values, dtype=np.float32), axis=1)\ntest_data_augmented['all_emotions'] = test_data_augmented[test_data_augmented.columns[-28:]].apply(lambda x: np.array(x.values, dtype=np.float32), axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dl = Dataset.from_pandas(train_data_augmented)\ntest_dl = Dataset.from_pandas(test_data_augmented)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_data['label']), y=train_data['label'])\nclass_weights = torch.tensor(class_weights, dtype=torch.float32)\nclass_weights","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"cardiffnlp/twitter-roberta-base-2022-154m\"\ntokenizer = AutoTokenizer.from_pretrained(model_card, use_Fast=False)\nmodel = CustomEmotionModel(model_card, num_labels = 2, num_emotions=28, class_weights=class_weights, device=device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_and_prepare(texts):\n    tokenized = tokenizer(texts['sentence'])\n    return {**tokenized, 'emotion_features': texts['all_emotions']}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dl = train_dl.map(tokenize_and_prepare, batched=True)\ntest_dl = test_dl.map(tokenize_and_prepare, batched=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=f'model',                 \n    learning_rate=5e-6,\n    per_device_train_batch_size=16,         \n    per_device_eval_batch_size=16,\n    lr_scheduler_type='linear',\n    label_smoothing_factor=0.1,\n    num_train_epochs=10,\n    weight_decay=1e-2,\n    eval_strategy=\"epoch\",       \n    save_strategy=\"no\",           \n    #save_safetensors=True,\n    #load_best_model_at_end=True,\n    report_to='none',\n    seed=SEED,\n    data_seed=SEED\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics(output_info):\n    \"\"\"\n    Compute various evaluation metrics for model predictions.\n    \n    Args:\n        output_info (tuple): A tuple containing the model predictions and the true labels.\n            - predictions (np.ndarray): The predicted labels from the model.\n            - labels (np.ndarray): The true labels.\n    \n    Returns:\n        dict: A dictionary containing the computed metrics:\n            - 'f1': The F1 score (macro average).\n            - 'accuracy': The accuracy score.\n            - 'precision': The precision score (macro average).\n            - 'recall': The recall score (macro average).\n    \"\"\"\n    predictions, labels = output_info\n    predictions = np.array(predictions)\n    labels = np.array(labels)\n    predictions = np.argmax(predictions, axis=-1)\n    \n    f1 = f1_score(labels, predictions, average=\"macro\", zero_division=0)\n    acc = accuracy_score(labels, predictions)\n    \n    return {\"f1-score\" : f1, \"Accuracy\" : acc}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dl,\n    eval_dataset=test_dl,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    class_weights=class_weights,\n    device=device,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\nprediction, labels, _ = trainer.predict(test_dl)\nprediction = np.argmax(prediction, axis=1)\ncm = confusion_matrix(y_true=labels, y_pred=prediction, normalize='all')\nprint(roc_auc_score(labels, prediction))\n\nConfusionMatrixDisplay(cm).plot()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}