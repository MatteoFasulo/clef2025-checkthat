{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10881030,"sourceType":"datasetVersion","datasetId":6742324,"isSourceIdPinned":false},{"sourceId":10918582,"sourceType":"datasetVersion","datasetId":6787896}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Subjectivity in News Articles\n\n## Group:\n- Luca Babboni - luca.babboni2@studio.unibo.it\n- Matteo Fasulo - matteo.fasulo@studio.unibo.it\n- Luca Tedeschini - luca.tedeschini3@studio.unibo.it\n\n## Description\n\nThis notebook addresses Task 1 proposed in [CheckThat Lab](https://checkthat.gitlab.io/clef2025/) of CLEF 2025. In this task, systems are challenged to distinguish whether a sentence from a news article expresses the subjective view of the author behind it or presents an objective view on the covered topic instead.\n\nThis is a binary classification tasks in which systems have to identify whether a text sequence (a sentence or a paragraph) is subjective (SUBJ) or objective (OBJ).\n\nThe task comprises three settings:\n\n* Monolingual: train and test on data in a given language\n* Multilingual: train and test on data comprising several languages\n* Zero-shot: train on several languages and test on unseen languages\n\ntraining data in five languages:\n* Arabic\n* Bulgarian\n* English\n* German\n* Italian\n\nThe official evaluation is macro-averaged F1 between the two classes.","metadata":{}},{"cell_type":"code","source":"%%capture\n%pip install -U transformers[torch] bitsandbytes trl peft sacremoses ctranslate2 accelerate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.kill(os.getpid(), 9)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nimport os\nimport gc\nfrom pathlib import Path\n\nimport csv\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, precision_recall_fscore_support\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nfrom sentence_transformers import SentenceTransformer\nfrom datasets import Dataset\nfrom huggingface_hub import notebook_login\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    Trainer, \n    TrainingArguments, \n    DataCollatorWithPadding, \n    BitsAndBytesConfig,\n    DebertaV2Model, \n    ModernBertModel, \n    DebertaV2Config, \n    ModernBertConfig, \n    pipeline \n)\nfrom transformers.trainer_utils import PredictionOutput","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:17.803540Z","iopub.execute_input":"2025-03-10T19:51:17.803853Z","iopub.status.idle":"2025-03-10T19:51:17.810464Z","shell.execute_reply.started":"2025-03-10T19:51:17.803829Z","shell.execute_reply":"2025-03-10T19:51:17.809597Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"SEED = 42\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ntqdm.pandas() # display tqdm on pandas apply functions\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:17.811561Z","iopub.execute_input":"2025-03-10T19:51:17.811987Z","iopub.status.idle":"2025-03-10T19:51:17.838521Z","shell.execute_reply.started":"2025-03-10T19:51:17.811948Z","shell.execute_reply":"2025-03-10T19:51:17.837360Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"np.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:17.839543Z","iopub.execute_input":"2025-03-10T19:51:17.839870Z","iopub.status.idle":"2025-03-10T19:51:17.860152Z","shell.execute_reply.started":"2025-03-10T19:51:17.839845Z","shell.execute_reply":"2025-03-10T19:51:17.859253Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Subjectivity:\n    def __init__(self, data_folder: str = 'data', seed: int = 42, device: str = 'cuda'):\n        self.seed = seed\n        self.device = device\n        self.languages = [language for language in os.listdir(data_folder)]\n\n        dataset = self.create_dataset(data_folder=data_folder)\n        self.dataset = dataset\n        \n        train, dev, test = self.get_splits(dataset, print_shapes=True)\n        self.train = train\n        self.dev = dev\n        self.test = test\n\n        self.all_data = self.get_per_lang_dataset()\n        \n\n    def create_dataset(self, data_folder: str = 'data'):\n        dataset = pd.DataFrame(columns=['sentence_id','sentence','label','lang','split'])\n        for language in os.listdir(data_folder):\n            for filename in os.listdir(f\"{data_folder}{os.sep}{language}\"):\n                if '.tsv' in filename:\n                    abs_path = f\"{data_folder}{os.sep}{language}{os.sep}{filename}\"\n                    df = pd.read_csv(abs_path, sep='\\t', quoting=csv.QUOTE_NONE)\n                    if 'solved_conflict' in df.columns:\n                        df.drop(columns=['solved_conflict'], inplace=True)\n                    df['lang'] = language\n                    df['split'] = Path(filename).stem\n                    dataset = pd.concat([dataset, df], axis=0)\n        return dataset\n\n    def get_splits(self, dataset: pd.DataFrame, print_shapes: bool = True):\n        train = dataset[dataset['split'].str.contains('train')].copy()\n        dev = dataset[(dataset['split'].str.contains('dev')) & ~(dataset['split'].str.contains('dev_test'))].copy()\n        test = dataset[dataset['split'].str.contains('dev_test')].copy()\n\n        # encode the target variable to int (0: obj; 1: subj)\n        train.loc[:, 'label'] = train['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n        dev.loc[:, 'label'] = dev['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n        test.loc[:, 'label'] = test['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n\n        # cast to int\n        train['label'] = train['label'].astype(int)\n        dev['label'] = dev['label'].astype(int)\n        test['label'] = test['label'].astype(int)\n\n        if print_shapes:\n            print(f\"Train: {train.shape}\")\n            print(f\"Dev: {dev.shape}\")\n            print(f\"Test: {test.shape}\")\n            \n        return train, dev, test\n\n    def get_per_lang_dataset(self):\n        \"\"\"\n        dataset_dict = {\n            'english': {\n                'train': ...\n                'dev': ...\n                'test': ...\n            },\n        }\n        \"\"\"\n        dataset_dict = {}\n        for language in self.languages:\n            dataset_dict[language] = {}\n            # get the train data\n            dataset_dict[language]['train'] = self.train[self.train['lang']==language].copy()\n            # get the dev data\n            dataset_dict[language]['dev'] = self.dev[self.dev['lang']==language].copy()\n            # get the test data\n            dataset_dict[language]['test'] = self.test[self.test['lang']==language].copy()\n        return dataset_dict\n\n    def print_label_distrib(self, dataset: pd.DataFrame):\n        print(dataset['label'].value_counts(normalize=True))\n\n    def get_baseline_model(self, model_name: str = \"paraphrase-multilingual-MiniLM-L12-v2\"):\n        vect = SentenceTransformer(model_name)\n        self.vect = vect\n        return vect\n\n    def train_baseline_model(self, vect, train_data: pd.DataFrame, test_data: pd.DataFrame, solver: str = 'saga'):\n        model = LogisticRegression(class_weight=\"balanced\", solver=solver, random_state=self.seed)\n        model.fit(X=vect.encode(train_data['sentence'].values), y=train_data['label'].values)\n        predictions = model.predict(X=vect.encode(test_data['sentence'].values)).tolist()\n\n        # eval performances\n        perfs = self.evaluate_model(gold_values=test_data['label'].values, predicted_values=predictions)\n\n        return perfs\n\n    def get_tokenizer(self, model_card: str = \"microsoft/mdeberta-v3-base\"):\n        tokenizer = AutoTokenizer.from_pretrained(model_card)\n        self.tokenizer = tokenizer\n        return tokenizer\n\n    def get_model(self, model_card: str = \"microsoft/mdeberta-v3-base\", *args, **kwargs):\n        model = AutoModelForSequenceClassification.from_pretrained(model_card, *args, **kwargs)\n        self.model = model\n        return model\n\n    def get_class_weights(self, dataset: pd.DataFrame):\n        class_weights = compute_class_weight('balanced', classes=np.unique(dataset['label']), y=dataset['label'])\n        return class_weights\n\n    def evaluate_model(self, gold_values, predicted_values):\n        acc = accuracy_score(gold_values, predicted_values)\n        m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(gold_values, predicted_values, average=\"macro\",\n                                                                   zero_division=0)\n        p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(gold_values, predicted_values, labels=[1],\n                                                                   zero_division=0)\n    \n        return {\n            'macro_F1': m_f1,\n            'macro_P': m_prec,\n            'macro_R': m_rec,\n            'SUBJ_F1': p_f1[0],\n            'SUBJ_P': p_prec[0],\n            'SUBJ_R': p_rec[0],\n            'accuracy': acc\n        }","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:17.863620Z","iopub.execute_input":"2025-03-10T19:51:17.864034Z","iopub.status.idle":"2025-03-10T19:51:17.884539Z","shell.execute_reply.started":"2025-03-10T19:51:17.863995Z","shell.execute_reply":"2025-03-10T19:51:17.883510Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"data_folder = '/kaggle/input/clef2025-checkthat/data' # data","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:17.886999Z","iopub.execute_input":"2025-03-10T19:51:17.887314Z","iopub.status.idle":"2025-03-10T19:51:17.907145Z","shell.execute_reply.started":"2025-03-10T19:51:17.887287Z","shell.execute_reply":"2025-03-10T19:51:17.906177Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"detector = Subjectivity(data_folder=data_folder, seed=SEED, device=device)","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:17.908391Z","iopub.execute_input":"2025-03-10T19:51:17.908802Z","iopub.status.idle":"2025-03-10T19:51:18.209127Z","shell.execute_reply.started":"2025-03-10T19:51:17.908765Z","shell.execute_reply":"2025-03-10T19:51:18.208094Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: (6418, 5)\nDev: (2401, 5)\nTest: (2332, 5)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"detector.print_label_distrib(detector.train)\ndetector.print_label_distrib(detector.dev)\ndetector.print_label_distrib(detector.test)","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:18.210253Z","iopub.execute_input":"2025-03-10T19:51:18.210646Z","iopub.status.idle":"2025-03-10T19:51:18.220177Z","shell.execute_reply.started":"2025-03-10T19:51:18.210608Z","shell.execute_reply":"2025-03-10T19:51:18.219112Z"},"trusted":true},"outputs":[{"name":"stdout","text":"label\n0    0.631349\n1    0.368651\nName: proportion, dtype: float64\nlabel\n0    0.612245\n1    0.387755\nName: proportion, dtype: float64\nlabel\n0    0.657376\n1    0.342624\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"notebook_login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = {}","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:18.221293Z","iopub.execute_input":"2025-03-10T19:51:18.221600Z","iopub.status.idle":"2025-03-10T19:51:18.237658Z","shell.execute_reply.started":"2025-03-10T19:51:18.221562Z","shell.execute_reply":"2025-03-10T19:51:18.236593Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L3700 (with some minor changes removing useless parts)\nclass CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, weights_dtype=torch.float32, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Ensure label_weights is a tensor\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, dtype=weights_dtype).to(self.args.device)\n        else:\n            self.class_weights = None\n\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        # Extract labels\n        labels = inputs.get(\"labels\")\n\n        # Forward pass\n        outputs = model(**inputs)\n\n        # Extract logits \n        logits = outputs.get('logits')\n\n        # Compute loss with class weights for imbalanced data handling\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss\n\n    def compute_best_threshold(self, dataset, ignore_keys=None, metric_key_prefix=\"test\"):\n        # Get raw predictions from parent class\n        output = super().predict(dataset, ignore_keys, metric_key_prefix)\n\n        # Convert logits to probabilities using softmax (for binary classification)\n        logits = output.predictions\n        logits_tensor = torch.tensor(logits)\n        probabilities = torch.softmax(logits_tensor, dim=-1).numpy()\n\n        # Calculate optimal threshold\n        labels = output.label_ids\n        thresholds = np.linspace(0.1, 0.9, 100) \n\n        best_threshold = 0.5  # Default threshold\n        best_f1 = 0\n\n        for threshold in thresholds:\n            predictions = (probabilities[:, 1] >= threshold).astype(int)\n            _, _, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"macro\", zero_division=0)\n            \n            if f1 > best_f1:\n                best_f1 = f1\n                best_threshold = threshold\n\n        # Return the best threshold found\n        return best_threshold\n        \n\n    def predict(self, dataset, threshold: float = 0.5, ignore_keys=None, metric_key_prefix=\"test\"):\n        # Get raw predictions from parent class\n        output = super().predict(dataset, ignore_keys, metric_key_prefix)\n        \n        # Convert logits to probabilities using softmax (for binary classification)\n        logits = output.predictions\n        logits_tensor = torch.tensor(logits)\n        probabilities = torch.softmax(logits_tensor, dim=-1).numpy()\n        \n        final_predictions = (probabilities[:, 1] >= threshold).astype(int)\n\n        # Update predictions in the output object\n        return PredictionOutput(\n            predictions=final_predictions,\n            label_ids=output.label_ids,\n            metrics=output.metrics\n        )\n\ndef tokenize_text(texts):\n    return tokenizer(texts['sentence'], padding=True, truncation=True, max_length=256, return_tensors='pt')\n\ndef evaluate_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    acc = accuracy_score(labels, predictions)\n    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                                zero_division=0)\n    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                                zero_division=0)\n\n    return {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }","metadata":{"execution":{"iopub.status.busy":"2025-03-10T19:51:18.238730Z","iopub.execute_input":"2025-03-10T19:51:18.239160Z","iopub.status.idle":"2025-03-10T19:51:18.258895Z","shell.execute_reply.started":"2025-03-10T19:51:18.239124Z","shell.execute_reply":"2025-03-10T19:51:18.257946Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# mDeBERTta v3 base (Arabic)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'arabic'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = detector.get_model(\n    model_card=f\"MatteoFasulo/mdeberta-v3-base-subjectivity-{language}\",\n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[language] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (Bulgarian)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'bulgarian'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = detector.get_model(\n    model_card=f\"MatteoFasulo/mdeberta-v3-base-subjectivity-{language}\", \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[language] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = detector.get_model(\n    model_card=f\"MatteoFasulo/mdeberta-v3-base-subjectivity-{language}\", \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[language] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTta v3 base (German)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'german'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = detector.get_model(\n    model_card=f\"MatteoFasulo/mdeberta-v3-base-subjectivity-{language}\", \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[language] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (italian)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'italian'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = detector.get_model(\n    model_card=f\"MatteoFasulo/mdeberta-v3-base-subjectivity-{language}\", \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[language] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mDeBERTa-base (multilingual)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'multilingual'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntrain_data = Dataset.from_pandas(detector.train)\ndev_data = Dataset.from_pandas(detector.dev)\ntest_data = Dataset.from_pandas(detector.test)\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\nclass_weights = detector.get_class_weights(detector.train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = detector.get_model(\n    model_card=f\"MatteoFasulo/mdeberta-v3-base-subjectivity-{language}\", \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    #weight_decay=1e-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[language] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# ModernBERT-base (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"answerdotai/ModernBERT-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = detector.get_model(\n    model_card=f\"MatteoFasulo/ModernBERT-base-subjectivity-{language}\", \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"ModernBERT-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    data_collator=collator_fn,\n    compute_metrics=evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults['english-modern-bert'] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Llama-3.2-1B (English)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"meta-llama/Llama-3.2-1B\" # meta-llama/Meta-Llama-3-8B\nlanguage = 'english'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit = False, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_card, add_prefix_space=True)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    f\"MatteoFasulo/Llama-3.2-1B-subjectivity-{language}\",\n    #quantization_config=quantization_config,\n    num_labels=2,\n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 6\nbatch_size = 16\nlr = 1e-4\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"Llama-3.2-1B-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[f\"llama3.2-1B-{language}\"] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Test - Translating Arab to English","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:51:20.095290Z","iopub.execute_input":"2025-03-10T19:51:20.095652Z","iopub.status.idle":"2025-03-10T19:51:20.478668Z","shell.execute_reply.started":"2025-03-10T19:51:20.095612Z","shell.execute_reply":"2025-03-10T19:51:20.477616Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"model_card = \"answerdotai/ModernBERT-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_card, \n    num_labels=2, \n    id2label={0: 'OBJ', 1: 'SUBJ'}, \n    label2id={'OBJ': 0, 'SUBJ': 1},\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:51:20.480234Z","iopub.execute_input":"2025-03-10T19:51:20.480597Z","iopub.status.idle":"2025-03-10T19:51:21.042658Z","shell.execute_reply.started":"2025-03-10T19:51:20.480571Z","shell.execute_reply":"2025-03-10T19:51:21.041816Z"}},"outputs":[{"name":"stderr","text":"Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"language = 'arabic'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:51:21.975804Z","iopub.execute_input":"2025-03-10T19:51:21.976182Z","iopub.status.idle":"2025-03-10T19:51:21.980337Z","shell.execute_reply.started":"2025-03-10T19:51:21.976151Z","shell.execute_reply":"2025-03-10T19:51:21.979402Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"!ct2-transformers-converter --model Helsinki-NLP/opus-mt-ar-en --output_dir opus-mt-ar-en","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ctranslate2\nimport transformers\n\ntranslator = ctranslate2.Translator(\"opus-mt-ar-en\", device='cuda')\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ar-en\")\n\ndef translate_text(raw_text):\n    source = tokenizer.convert_ids_to_tokens(tokenizer.encode(raw_text))\n    results = translator.translate_batch([source])\n    target = results[0].hypotheses[0]\n    translation = tokenizer.decode(tokenizer.convert_tokens_to_ids(target))\n    return translation","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['train']['translated_sentence'] = detector.all_data[language]['train']['sentence'].progress_apply(translate_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['dev']['translated_sentence'] = detector.all_data[language]['dev']['sentence'].progress_apply(translate_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['test']['translated_sentence'] = detector.all_data[language]['test']['sentence'].progress_apply(translate_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['train'].to_csv('/kaggle/working/train_ar.csv')\ndetector.all_data[language]['dev'].to_csv('/kaggle/working/dev_ar.csv')\ndetector.all_data[language]['test'].to_csv('/kaggle/working/dev_test_ar.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detector.all_data[language]['train'] = pd.read_csv('/kaggle/working/train_ar.csv')\ndetector.all_data[language]['dev'] = pd.read_csv('/kaggle/working/dev_ar.csv')\ndetector.all_data[language]['test'] = pd.read_csv('/kaggle/working/dev_test_ar.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:51:25.850487Z","iopub.execute_input":"2025-03-10T19:51:25.850872Z","iopub.status.idle":"2025-03-10T19:51:25.904664Z","shell.execute_reply.started":"2025-03-10T19:51:25.850840Z","shell.execute_reply":"2025-03-10T19:51:25.903809Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"epochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\n\ntrain_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ndef tokenize_text(texts):\n    return tokenizer(texts['translated_sentence'], padding=True, truncation=True, max_length=256, return_tensors='pt')\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:51:27.543994Z","iopub.execute_input":"2025-03-10T19:51:27.544377Z","iopub.status.idle":"2025-03-10T19:51:28.527007Z","shell.execute_reply.started":"2025-03-10T19:51:27.544350Z","shell.execute_reply":"2025-03-10T19:51:28.525879Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8989b3f92fe94b02b3116efdf6504cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/467 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0329a7491f9b45fd8ba8cc122cf09393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/748 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdcbcbe3e680470284839c1916c770fe"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"ModernBERT-base-subjectivity-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:51:28.528316Z","iopub.execute_input":"2025-03-10T19:51:28.528658Z","iopub.status.idle":"2025-03-10T19:51:28.591579Z","shell.execute_reply.started":"2025-03-10T19:51:28.528632Z","shell.execute_reply":"2025-03-10T19:51:28.590469Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:51:36.915076Z","iopub.execute_input":"2025-03-10T19:51:36.915389Z","iopub.status.idle":"2025-03-10T19:51:37.339772Z","shell.execute_reply.started":"2025-03-10T19:51:36.915365Z","shell.execute_reply":"2025-03-10T19:51:37.338947Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:51:37.379301Z","iopub.execute_input":"2025-03-10T19:51:37.379674Z","iopub.status.idle":"2025-03-10T20:01:01.227001Z","shell.execute_reply.started":"2025-03-10T19:51:37.379644Z","shell.execute_reply":"2025-03-10T20:01:01.226112Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='918' max='918' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [918/918 09:22, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Macro F1</th>\n      <th>Macro P</th>\n      <th>Macro R</th>\n      <th>Subj F1</th>\n      <th>Subj P</th>\n      <th>Subj R</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.685731</td>\n      <td>0.538930</td>\n      <td>0.557348</td>\n      <td>0.555746</td>\n      <td>0.556701</td>\n      <td>0.475352</td>\n      <td>0.671642</td>\n      <td>0.539615</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.696614</td>\n      <td>0.544413</td>\n      <td>0.557714</td>\n      <td>0.550013</td>\n      <td>0.424419</td>\n      <td>0.510490</td>\n      <td>0.363184</td>\n      <td>0.576017</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.726701</td>\n      <td>0.534970</td>\n      <td>0.544084</td>\n      <td>0.539343</td>\n      <td>0.420455</td>\n      <td>0.490066</td>\n      <td>0.368159</td>\n      <td>0.563169</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.647700</td>\n      <td>0.755695</td>\n      <td>0.525088</td>\n      <td>0.525070</td>\n      <td>0.525184</td>\n      <td>0.463054</td>\n      <td>0.458537</td>\n      <td>0.467662</td>\n      <td>0.533191</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.647700</td>\n      <td>0.852189</td>\n      <td>0.534913</td>\n      <td>0.536520</td>\n      <td>0.535359</td>\n      <td>0.450262</td>\n      <td>0.475138</td>\n      <td>0.427861</td>\n      <td>0.550321</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.647700</td>\n      <td>0.868179</td>\n      <td>0.520145</td>\n      <td>0.520679</td>\n      <td>0.520321</td>\n      <td>0.441026</td>\n      <td>0.455026</td>\n      <td>0.427861</td>\n      <td>0.533191</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=918, training_loss=0.5380588772509872, metrics={'train_runtime': 563.0125, 'train_samples_per_second': 26.067, 'train_steps_per_second': 1.631, 'total_flos': 2471178561478704.0, 'train_loss': 0.5380588772509872, 'epoch': 6.0})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[f\"llama3.2-1B-{language}\"] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language})\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T20:01:01.228261Z","iopub.execute_input":"2025-03-10T20:01:01.228587Z","iopub.status.idle":"2025-03-10T20:01:13.075695Z","shell.execute_reply.started":"2025-03-10T20:01:01.228562Z","shell.execute_reply":"2025-03-10T20:01:13.074635Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"{'macro_F1': 0.5374902369174694, 'macro_P': 0.5377207178048693, 'macro_R': 0.5382043343653251, 'SUBJ_F1': 0.48802395209580846, 'SUBJ_P': 0.47246376811594204, 'SUBJ_R': 0.5046439628482973, 'accuracy': 0.5427807486631016}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# mdeberta-v3-base (english + sentiment)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, model_name=\"microsoft/mdeberta-v3-base\", num_labels=2, sentiment_dim=3):\n        super().__init__()\n        self.model = DebertaV2Model.from_pretrained(model_name)\n        self.config = DebertaV2Config\n        hidden_size = self.model.config.hidden_size\n  \n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size + sentiment_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, num_labels)\n        )\n\n    def forward(self, input_ids, positive, neutral, negative, attention_mask=None, labels=None):\n        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n        cls_embedding = last_hidden_state[:, 0, :]  # Get CLS token embedding\n        \n        # Sentiment features as a single tensor\n        sentiment_features = torch.stack((positive, neutral, negative), dim=1)  # Shape: (batch_size, 3)\n        \n        # Combine CLS embedding with sentiment features\n        combined_features = torch.cat((cls_embedding, sentiment_features), dim=1)\n        \n        # Classification head\n        logits = self.classifier(combined_features)\n        \n        return {'logits': logits}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'english'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = CustomModel(\n    model_name=f\"MatteoFasulo/mdeberta-v3-base-subjectivity-sentiment-{language}\", \n    num_labels=2, \n    sentiment_dim=3\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipe = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\", tokenizer=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\", top_k=None)\n\ndef extract_sentiment(text):\n    sentiments = pipe(text)[0]\n    return {k:v for k,v in [(list(sentiment.values())[0], list(sentiment.values())[1]) for sentiment in sentiments]}\n\ndetector.all_data[language]['train'][['positive', 'neutral', 'negative']] = detector.all_data[language]['train'].progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')\ndetector.all_data[language]['dev'][['positive', 'neutral', 'negative']] = detector.all_data[language]['dev'].progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')\ndetector.all_data[language]['test'][['positive', 'neutral', 'negative']] = detector.all_data[language]['test'].progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-sentiment-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[f\"{language}-sentiment\"] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language}-sentiment)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mdeberta-v3-base (german + sentiment)","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    torch.cuda.empty_cache()\n\nif 'model' in locals() or 'model' in globals():\n    del model\n    print(\"Model deleted!\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, model_name=\"microsoft/mdeberta-v3-base\", num_labels=2, sentiment_dim=3):\n        super().__init__()\n        self.model = DebertaV2Model.from_pretrained(model_name)\n        self.config = DebertaV2Config\n        hidden_size = self.model.config.hidden_size\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size + sentiment_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, num_labels)\n        )\n\n    def forward(self, input_ids, positive, neutral, negative, attention_mask=None, labels=None):\n        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n        pooled_output = last_hidden_state[:, 0, :]  # Prendiamo il token [CLS] (prima posizione)\n        \n        # Concatenate with sentiment features\n        positive = positive.unsqueeze(1)\n        neutral = neutral.unsqueeze(1)\n        negative = negative.unsqueeze(1)\n        sentiment_features = torch.cat((positive, neutral, negative), dim=1)\n        combined_features = torch.cat((pooled_output, sentiment_features), dim=1)\n        \n        # Pass through custom classification head\n        logits = self.classifier(combined_features)\n        \n        return {'logits': logits}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'german'\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\nmodel = CustomModel(\n    model_name=model_card, \n    num_labels=2, \n    sentiment_dim=3\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipe = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\", tokenizer=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\", top_k=None)\n\ndef extract_sentiment(text):\n    sentiments = pipe(text)[0]\n    return {k:v for k,v in [(list(sentiment.values())[0], list(sentiment.values())[1]) for sentiment in sentiments]}\n\ndetector.all_data[language]['train'][['positive', 'neutral', 'negative']] = detector.all_data[language]['train'].progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')\ndetector.all_data[language]['dev'][['positive', 'neutral', 'negative']] = detector.all_data[language]['dev'].progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')\ndetector.all_data[language]['test'][['positive', 'neutral', 'negative']] = detector.all_data[language]['test'].progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = Dataset.from_pandas(detector.all_data[language]['train'])\ndev_data = Dataset.from_pandas(detector.all_data[language]['dev'])\ntest_data = Dataset.from_pandas(detector.all_data[language]['test'])\n\ntrain_data = train_data.map(tokenize_text, batched=True)\ndev_data = dev_data.map(tokenize_text, batched=True)\ntest_data = test_data.map(tokenize_text, batched=True)\n\ncollator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\nclass_weights = detector.get_class_weights(detector.all_data[language]['train'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training args\ntraining_args = TrainingArguments(\n    output_dir=f\"mdeberta-v3-base-subjectivity-sentiment-{language}\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_data,\n    eval_dataset = dev_data,\n    data_collator = collator_fn,\n    compute_metrics = evaluate_metrics,\n    class_weights=class_weights,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_thr = trainer.compute_best_threshold(dataset=dev_data)\npred_info = trainer.predict(dataset=test_data, threshold=best_thr)\n\npredictions, labels = pred_info.predictions, pred_info.label_ids\n\nacc = accuracy_score(labels, predictions)\nm_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                            zero_division=0)\np_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                            zero_division=0)\nstats = {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc\n    }\n\nprint(stats)\nresults[f\"{language}-sentiment\"] = stats\n\ncm = confusion_matrix(labels, predictions, normalize='all')\nConfusionMatrixDisplay(cm, display_labels=['OBJ', 'SUBJ']).plot()\nplt.title(f\"Confusion Matrix ({language}-sentiment)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(results).T.sort_values(by='macro_F1', ascending=False).round(4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n# Zero shot inference","metadata":{}},{"cell_type":"markdown","source":"## Utility function\n\nThis function can be then integrated in the Subjectivity class","metadata":{}},{"cell_type":"code","source":"def zero_shot_prepare_data(train_languages : list,\n                           train : pd.DataFrame,\n                           dev : pd.DataFrame,\n                           test : pd.DataFrame):\n\n    \n    train_set = train[train[\"lang\"].isin(train_languages)].copy()\n    dev_set = dev[~dev[\"lang\"].isin(train_languages)].copy()\n    test_set = test[~test[\"lang\"].isin(train_languages)].copy()\n\n    return train_set, dev_set, test_set","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_name(names : tuple):\n    generated_name = \"\"\n    for x in names:\n        generated_name = generated_name + x.capitalize()[:2]\n    return generated_name","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom loop to test triplets","metadata":{}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, model_name=\"microsoft/mdeberta-v3-base\", num_labels=2, sentiment_dim=3):\n        super().__init__()\n        self.model = DebertaV2Model.from_pretrained(model_name)\n        self.config = DebertaV2Config\n        hidden_size = self.model.config.hidden_size\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size + sentiment_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, num_labels)\n        )\n\n    def forward(self, input_ids, positive, neutral, negative, attention_mask=None, labels=None):\n        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n        pooled_output = last_hidden_state[:, 0, :]  # Prendiamo il token [CLS] (prima posizione)\n        \n        # Concatenate with sentiment features\n        positive = positive.unsqueeze(1)\n        neutral = neutral.unsqueeze(1)\n        negative = negative.unsqueeze(1)\n        sentiment_features = torch.cat((positive, neutral, negative), dim=1)\n        combined_features = torch.cat((pooled_output, sentiment_features), dim=1)\n        \n        # Pass through custom classification head\n        logits = self.classifier(combined_features)\n        \n        return {'logits': logits}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_sentiment(text):\n    sentiments = pipe(text)[0]\n    return {k:v for k,v in [(list(sentiment.values())[0], list(sentiment.values())[1]) for sentiment in sentiments]}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import itertools\nresults = {}\nmodel_card = \"microsoft/mdeberta-v3-base\"\ntokenizer = detector.get_tokenizer(model_card=model_card)\n\nepochs = 6\nbatch_size = 16\nlr = 1e-5\nweight_decay = 0.0\nlabel_smoothing = 0.0\n\ntraining_args = TrainingArguments(\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    weight_decay=weight_decay,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    #warmup_ratio=0.5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    report_to=\"none\"\n)\n\npipe = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\", tokenizer=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\", top_k=None)\n\n\n\nfor i, group in enumerate(itertools.combinations(detector.languages, 3)):\n    print(f\"TESTING {i} - {group}\")\n    with torch.no_grad():\n        torch.cuda.empty_cache()\n    if 'model' in locals() or 'model' in globals():\n        del model\n        print(\"Model deleted!\")\n    gc.collect()\n    \n    group_name = generate_name(group)\n\n    zs_train, zs_dev, zs_test = zero_shot_prepare_data(group, detector.train, detector.dev, detector.test)\n\n    language = group_name+'-NoSentiment'\n\n\n    \n    train_data = Dataset.from_pandas(zs_train)\n    dev_data = Dataset.from_pandas(zs_dev)\n    test_data = Dataset.from_pandas(zs_test)\n    \n    train_data = train_data.map(tokenize_text, batched=True)\n    dev_data = dev_data.map(tokenize_text, batched=True)\n    test_data = test_data.map(tokenize_text, batched=True)\n    \n    class_weights = detector.get_class_weights(zs_train)\n\n    model = detector.get_model(\n        model_card=model_card, \n        num_labels=2, \n        id2label={0: 'OBJ', 1: 'SUBJ'}, \n        label2id={'OBJ': 0, 'SUBJ': 1},\n        output_attentions = False,\n        output_hidden_states = False\n    )\n    \n    collator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\n    trainer = CustomTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_data,\n        eval_dataset=dev_data,\n        data_collator=collator_fn,\n        compute_metrics=evaluate_metrics,\n        class_weights=class_weights,\n    )\n\n    trainer.train()\n\n    pred_info = trainer.predict(test_data)\n    predictions, labels = pred_info.predictions, pred_info.label_ids\n    \n    acc = accuracy_score(labels, predictions)\n    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                                zero_division=0)\n    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                                zero_division=0)\n    stats = {\n            'macro_F1': m_f1,\n            'macro_P': m_prec,\n            'macro_R': m_rec,\n            'SUBJ_F1': p_f1[0],\n            'SUBJ_P': p_prec[0],\n            'SUBJ_R': p_rec[0],\n            'accuracy': acc\n        }\n    \n    results[language] = stats\n\n    \n    with torch.no_grad():\n        torch.cuda.empty_cache()\n    if 'model' in locals() or 'model' in globals():\n        del model\n        print(\"Model deleted!\")\n    gc.collect()\n\n    language = group_name+'-Sentiment'\n    \n    model = CustomModel(\n        model_name=model_card, \n        num_labels=2, \n        sentiment_dim=3\n    )\n\n\n\n    zs_train[['positive', 'neutral', 'negative']] = zs_train.progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')\n    zs_dev[['positive', 'neutral', 'negative']] = zs_dev.progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')\n    zs_test[['positive', 'neutral', 'negative']] = zs_test.progress_apply(lambda x: extract_sentiment(x['sentence']), axis=1, result_type='expand')\n\n    train_data = Dataset.from_pandas(zs_train)\n    dev_data = Dataset.from_pandas(zs_dev)\n    test_data = Dataset.from_pandas(zs_test)\n\n    train_data = train_data.map(tokenize_text, batched=True)\n    dev_data = dev_data.map(tokenize_text, batched=True)\n    test_data = test_data.map(tokenize_text, batched=True)\n\n    collator_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n\n    trainer = CustomTrainer(\n        model = model,\n        args = training_args,\n        train_dataset = train_data,\n        eval_dataset = dev_data,\n        data_collator = collator_fn,\n        compute_metrics = evaluate_metrics,\n        class_weights=class_weights,\n    )\n\n    trainer.train()\n\n    pred_info = trainer.predict(test_data)\n    predictions, labels = pred_info.predictions, pred_info.label_ids\n    \n    acc = accuracy_score(labels, predictions)\n    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n                                                                zero_division=0)\n    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n                                                                zero_division=0)\n    stats = {\n            'macro_F1': m_f1,\n            'macro_P': m_prec,\n            'macro_R': m_rec,\n            'SUBJ_F1': p_f1[0],\n            'SUBJ_P': p_prec[0],\n            'SUBJ_R': p_rec[0],\n            'accuracy': acc\n        }\n    \n    results[language] = stats\n    \n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(results).T.sort_values(by='macro_F1', ascending=False).round(4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"pd.DataFrame(results).to_csv(\"results.csv\")","metadata":{}},{"cell_type":"code","source":"dataframe = pd.DataFrame(results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataframe.to_csv(\"results.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}