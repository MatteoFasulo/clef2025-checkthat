{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10854945,"sourceType":"datasetVersion","datasetId":6742324}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Subjectivity in News Articles\n\n## Group:\n- Luca Babboni - luca.babboni2@studio.unibo.it\n- Matteo Fasulo - matteo.fasulo@studio.unibo.it\n- Luca Tedeschini - luca.tedeschini3@studio.unibo.it\n\n## Description\n\nThis notebook addresses Task 1 proposed in [CheckThat Lab](https://checkthat.gitlab.io/clef2025/) of CLEF 2025. In this task, systems are challenged to distinguish whether a sentence from a news article expresses the subjective view of the author behind it or presents an objective view on the covered topic instead.\n\nThis is a binary classification tasks in which systems have to identify whether a text sequence (a sentence or a paragraph) is subjective (SUBJ) or objective (OBJ).\n\nThe task comprises three settings:\n\n* Monolingual: train and test on data in a given language\n* Multilingual: train and test on data comprising several languages\n* Zero-shot: train on several languages and test on unseen languages\n\ntraining data in five languages:\n* Arabic\n* Bulgarian\n* English\n* German\n* Italian\n\nThe official evaluation is macro-averaged F1 between the two classes.","metadata":{}},{"cell_type":"code","source":"import os\nimport csv\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom joblib import delayed, Parallel\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, f1_score\n\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\n\nfrom sentence_transformers import SentenceTransformer\nfrom datasets import Dataset\nfrom huggingface_hub import notebook_login\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, RobertaTokenizerFast, TFRobertaForSequenceClassification, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:41:06.426542Z","iopub.execute_input":"2025-02-27T17:41:06.426876Z","iopub.status.idle":"2025-02-27T17:41:06.431733Z","shell.execute_reply.started":"2025-02-27T17:41:06.426850Z","shell.execute_reply":"2025-02-27T17:41:06.430948Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"SEED = 42\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:01.515692Z","iopub.execute_input":"2025-02-27T17:28:01.515980Z","iopub.status.idle":"2025-02-27T17:28:01.523130Z","shell.execute_reply.started":"2025-02-27T17:28:01.515953Z","shell.execute_reply":"2025-02-27T17:28:01.522366Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_filepath = '/kaggle/input/clef2025-checkthat/data/english/train_en.tsv'\ntest_filepath = '/kaggle/input/clef2025-checkthat/data/english/dev_test_en.tsv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:01.816284Z","iopub.execute_input":"2025-02-27T17:28:01.816567Z","iopub.status.idle":"2025-02-27T17:28:01.819833Z","shell.execute_reply.started":"2025-02-27T17:28:01.816547Z","shell.execute_reply":"2025-02-27T17:28:01.818938Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_data = pd.read_csv(train_filepath, sep='\\t', quoting=csv.QUOTE_NONE)\ntest_data = pd.read_csv(test_filepath, sep='\\t', quoting=csv.QUOTE_NONE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:01.991211Z","iopub.execute_input":"2025-02-27T17:28:01.991574Z","iopub.status.idle":"2025-02-27T17:28:02.044564Z","shell.execute_reply.started":"2025-02-27T17:28:01.991545Z","shell.execute_reply":"2025-02-27T17:28:02.043675Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_data.label.value_counts(), test_data.label.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:02.175992Z","iopub.execute_input":"2025-02-27T17:28:02.176604Z","iopub.status.idle":"2025-02-27T17:28:02.193608Z","shell.execute_reply.started":"2025-02-27T17:28:02.176560Z","shell.execute_reply":"2025-02-27T17:28:02.192732Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(label\n OBJ     532\n SUBJ    298\n Name: count, dtype: int64,\n label\n OBJ     362\n SUBJ    122\n Name: count, dtype: int64)"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Legend:\n* Objective -> 0\n* Subjective -> 1","metadata":{}},{"cell_type":"code","source":"train_data['label'] = train_data['label'].apply(lambda x: 1 if x == 'SUBJ' else 0)\ntest_data['label'] = test_data['label'].apply(lambda x: 1 if x == 'SUBJ' else 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:03.374668Z","iopub.execute_input":"2025-02-27T17:28:03.374982Z","iopub.status.idle":"2025-02-27T17:28:03.380630Z","shell.execute_reply.started":"2025-02-27T17:28:03.374955Z","shell.execute_reply":"2025-02-27T17:28:03.379789Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"notebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:06.879828Z","iopub.execute_input":"2025-02-27T17:28:06.880110Z","iopub.status.idle":"2025-02-27T17:28:06.897022Z","shell.execute_reply.started":"2025-02-27T17:28:06.880090Z","shell.execute_reply":"2025-02-27T17:28:06.896122Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d731d3fcd71b41f4942e25363b8e14d7"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"code","source":"vect = SentenceTransformer(\"all-mpnet-base-v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:28.506016Z","iopub.execute_input":"2025-02-27T17:28:28.506308Z","iopub.status.idle":"2025-02-27T17:28:34.358502Z","shell.execute_reply.started":"2025-02-27T17:28:28.506287Z","shell.execute_reply":"2025-02-27T17:28:34.357423Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60d624353f1a40dbabb7de4ad898af79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8762b1650c2a40418457f8a1cf52af06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"538b0de0444449a9881d942010f7b02d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b84bfa92371d4804a83a3659506c8e64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f9d65073cb74c83a70ffee3a2fc6f1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b88697aa68a5417bb64adeef1578cd6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cea29e8805c544cd8d67844745dd30b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e764c5716c384edf95e40fe33cc3426a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f787a3410b411dba463528331d940f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d3f629702f465a832033767aff2f69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a84bdf3b8ba4b699ec2f1b91cd02971"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"model = LogisticRegression(class_weight=\"balanced\", random_state=SEED)\nmodel.fit(X=vect.encode(train_data['sentence'].values), y=train_data['label'].values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:34.359742Z","iopub.execute_input":"2025-02-27T17:28:34.360046Z","iopub.status.idle":"2025-02-27T17:28:36.222518Z","shell.execute_reply.started":"2025-02-27T17:28:34.360019Z","shell.execute_reply":"2025-02-27T17:28:36.221627Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/26 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bab9d1efc72481da7573df9f8259a10"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(class_weight='balanced', random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"predictions = model.predict(X=vect.encode(test_data['sentence'].values)).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:36.223950Z","iopub.execute_input":"2025-02-27T17:28:36.224203Z","iopub.status.idle":"2025-02-27T17:28:37.043837Z","shell.execute_reply.started":"2025-02-27T17:28:36.224181Z","shell.execute_reply":"2025-02-27T17:28:37.043163Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c7539af8a694dc69e7d52597a7b7dd1"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"pred_df = pd.DataFrame()\npred_df['sentence_id'] = test_data['sentence_id']\npred_df['label'] = predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:37.044683Z","iopub.execute_input":"2025-02-27T17:28:37.044918Z","iopub.status.idle":"2025-02-27T17:28:37.052402Z","shell.execute_reply.started":"2025-02-27T17:28:37.044899Z","shell.execute_reply":"2025-02-27T17:28:37.051687Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate_model(gold_values, predicted_values):\n    acc = accuracy_score(gold_values, predicted_values)\n    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(gold_values, predicted_values, average=\"macro\",\n                                                               zero_division=0)\n    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(gold_values, predicted_values, labels=[1],\n                                                               zero_division=0)\n    #roc_auc = roc_auc_score(gold_values, predicted_probabilities)\n\n    return {\n        'macro_F1': m_f1,\n        'macro_P': m_prec,\n        'macro_R': m_rec,\n        'SUBJ_F1': p_f1[0],\n        'SUBJ_P': p_prec[0],\n        'SUBJ_R': p_rec[0],\n        'accuracy': acc,\n        #'roc_auc': roc_auc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:37.053151Z","iopub.execute_input":"2025-02-27T17:28:37.053363Z","iopub.status.idle":"2025-02-27T17:28:37.069279Z","shell.execute_reply.started":"2025-02-27T17:28:37.053345Z","shell.execute_reply":"2025-02-27T17:28:37.068678Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"evaluate_model(gold_values=test_data.label.values, predicted_values=predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:37.069875Z","iopub.execute_input":"2025-02-27T17:28:37.070076Z","iopub.status.idle":"2025-02-27T17:28:37.090774Z","shell.execute_reply.started":"2025-02-27T17:28:37.070058Z","shell.execute_reply":"2025-02-27T17:28:37.089936Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'macro_F1': 0.6389887849969365,\n 'macro_P': 0.6864212513484358,\n 'macro_R': 0.6252151073272348,\n 'SUBJ_F1': 0.42268041237113396,\n 'SUBJ_P': 0.5694444444444444,\n 'SUBJ_R': 0.3360655737704918,\n 'accuracy': 0.768595041322314}"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# Twitter RoBERTa-base 2022 154M","metadata":{}},{"cell_type":"code","source":"model_card = \"cardiffnlp/twitter-roberta-base-2022-154m\"\ntokenizer = AutoTokenizer.from_pretrained(model_card, use_Fast=False)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_card, num_labels=2, id2label={0: 'OBJ', 1: 'SUBJ'}, label2id={'OBJ': 0, 'SUBJ': 1})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:40.701729Z","iopub.execute_input":"2025-02-27T17:28:40.702014Z","iopub.status.idle":"2025-02-27T17:28:45.722382Z","shell.execute_reply.started":"2025-02-27T17:28:40.701992Z","shell.execute_reply":"2025-02-27T17:28:45.721312Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245437ee26f34660ae1803cfc12c0337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13761303dbf8441982a337d6a917b45b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed05b7848f9142eda6334bf7cc87172c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d43756de69c4a8493ca329d23d317a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0607310e5b184de298ea488ffda7bb4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92a4d049cf5f4a63a99f7833332e1406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad081dd3dc0f4b6cb32a5a06c913df35"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-2022-154m and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def preprocess_text(texts):\n    return tokenizer(texts['sentence'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:45.724178Z","iopub.execute_input":"2025-02-27T17:28:45.724463Z","iopub.status.idle":"2025-02-27T17:28:45.729206Z","shell.execute_reply.started":"2025-02-27T17:28:45.724426Z","shell.execute_reply":"2025-02-27T17:28:45.728414Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_dl = Dataset.from_pandas(train_data)\ntest_dl = Dataset.from_pandas(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:45.730674Z","iopub.execute_input":"2025-02-27T17:28:45.730872Z","iopub.status.idle":"2025-02-27T17:28:45.771197Z","shell.execute_reply.started":"2025-02-27T17:28:45.730856Z","shell.execute_reply":"2025-02-27T17:28:45.770387Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_dl = train_dl.map(preprocess_text, batched=True)\ntest_dl = test_dl.map(preprocess_text, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:45.772570Z","iopub.execute_input":"2025-02-27T17:28:45.772994Z","iopub.status.idle":"2025-02-27T17:28:45.990925Z","shell.execute_reply.started":"2025-02-27T17:28:45.772972Z","shell.execute_reply":"2025-02-27T17:28:45.989924Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/830 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3f5206d49104846a40837c6dfe626f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ac5032f5bf4440bab9c979a8ca20f0c"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:45.991887Z","iopub.execute_input":"2025-02-27T17:28:45.992211Z","iopub.status.idle":"2025-02-27T17:28:45.995979Z","shell.execute_reply.started":"2025-02-27T17:28:45.992179Z","shell.execute_reply":"2025-02-27T17:28:45.995151Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=f'model',                 \n    learning_rate=5e-6,\n    per_device_train_batch_size=16,         \n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=1e-4,\n    eval_strategy=\"epoch\",       \n    save_strategy=\"no\",           \n    #save_safetensors=True,\n    #load_best_model_at_end=True,\n    report_to='none',\n    seed=SEED,\n    data_seed=SEED\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:45.996723Z","iopub.execute_input":"2025-02-27T17:28:45.996951Z","iopub.status.idle":"2025-02-27T17:28:46.037988Z","shell.execute_reply.started":"2025-02-27T17:28:45.996923Z","shell.execute_reply":"2025-02-27T17:28:46.037392Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L3700 (with some minor changes removing useless parts)\nclass CustomTrainer(Trainer):\n    def __init__(self, class_weights, device, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # You pass the class weights when instantiating the Trainer\n        self.class_weights = class_weights\n        self.device = device\n\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        if self.label_smoother is not None and \"labels\" in inputs:\n            labels = inputs.pop(\"labels\")\n        else:\n            labels = None\n        outputs = model(**inputs)\n        if self.args.past_index >= 0:\n            self._past = outputs[self.args.past_index]\n\n        if labels is not None:\n            loss = self.label_smoother(outputs, labels)\n        else:\n            # We extract the logits from the model outputs\n            logits = outputs.get('logits')\n            # We compute the loss manually passing the class weights to the loss function\n            criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(self.device)) # Modified to use the class weights\n            # We compute the loss using the modified criterion\n            loss = criterion(logits, inputs['labels'])\n\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:46.039081Z","iopub.execute_input":"2025-02-27T17:28:46.039357Z","iopub.status.idle":"2025-02-27T17:28:46.044937Z","shell.execute_reply.started":"2025-02-27T17:28:46.039337Z","shell.execute_reply":"2025-02-27T17:28:46.044228Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_data['label']), y=train_data['label'])\nclass_weights = torch.tensor(class_weights, dtype=torch.float32)\nclass_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:46.046312Z","iopub.execute_input":"2025-02-27T17:28:46.046561Z","iopub.status.idle":"2025-02-27T17:28:46.075793Z","shell.execute_reply.started":"2025-02-27T17:28:46.046542Z","shell.execute_reply":"2025-02-27T17:28:46.075109Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"tensor([0.7801, 1.3926])"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"def compute_metrics(output_info):\n    \"\"\"\n    Compute various evaluation metrics for model predictions.\n    \n    Args:\n        output_info (tuple): A tuple containing the model predictions and the true labels.\n            - predictions (np.ndarray): The predicted labels from the model.\n            - labels (np.ndarray): The true labels.\n    \n    Returns:\n        dict: A dictionary containing the computed metrics:\n            - 'f1': The F1 score (macro average).\n            - 'accuracy': The accuracy score.\n            - 'precision': The precision score (macro average).\n            - 'recall': The recall score (macro average).\n    \"\"\"\n    predictions, labels = output_info\n    predictions = np.array(predictions)\n    labels = np.array(labels)\n    predictions = np.argmax(predictions, axis=-1)\n    \n    f1 = f1_score(labels, predictions, average=\"macro\", zero_division=0)\n    acc = accuracy_score(labels, predictions)\n    \n    return {\"f1-score\" : f1, \"Accuracy\" : acc}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:58:06.831095Z","iopub.execute_input":"2025-02-27T17:58:06.831437Z","iopub.status.idle":"2025-02-27T17:58:06.836143Z","shell.execute_reply.started":"2025-02-27T17:58:06.831409Z","shell.execute_reply":"2025-02-27T17:58:06.835247Z"}},"outputs":[],"execution_count":122},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dl,\n    eval_dataset=test_dl,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    class_weights=class_weights,\n    device=device,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:46.927862Z","iopub.execute_input":"2025-02-27T17:28:46.928159Z","iopub.status.idle":"2025-02-27T17:28:47.121813Z","shell.execute_reply.started":"2025-02-27T17:28:46.928137Z","shell.execute_reply":"2025-02-27T17:28:47.121104Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:28:47.184021Z","iopub.execute_input":"2025-02-27T17:28:47.184448Z","iopub.status.idle":"2025-02-27T17:30:07.832474Z","shell.execute_reply.started":"2025-02-27T17:28:47.184416Z","shell.execute_reply":"2025-02-27T17:30:07.831760Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='520' max='520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [520/520 01:19, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1-score</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.688935</td>\n      <td>0.629009</td>\n      <td>0.679752</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.603510</td>\n      <td>0.576875</td>\n      <td>0.743802</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.588981</td>\n      <td>0.636934</td>\n      <td>0.772727</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.549509</td>\n      <td>0.708090</td>\n      <td>0.805785</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.618697</td>\n      <td>0.708090</td>\n      <td>0.805785</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.666957</td>\n      <td>0.707937</td>\n      <td>0.809917</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.667111</td>\n      <td>0.710021</td>\n      <td>0.811983</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.736481</td>\n      <td>0.709744</td>\n      <td>0.816116</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>0.732077</td>\n      <td>0.709902</td>\n      <td>0.814050</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.357400</td>\n      <td>0.732407</td>\n      <td>0.709902</td>\n      <td>0.814050</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=520, training_loss=0.34930706849465004, metrics={'train_runtime': 80.0614, 'train_samples_per_second': 103.67, 'train_steps_per_second': 6.495, 'total_flos': 295059520812600.0, 'train_loss': 0.34930706849465004, 'epoch': 10.0})"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"# Emotions","metadata":{}},{"cell_type":"code","source":"model_card = \"arpanghoshal/EmoRoBERTa\"\ntokenizer = RobertaTokenizerFast.from_pretrained(model_card)\nmodel = TFRobertaForSequenceClassification.from_pretrained(model_card)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:30:20.594953Z","iopub.execute_input":"2025-02-27T17:30:20.595235Z","iopub.status.idle":"2025-02-27T17:30:26.401760Z","shell.execute_reply.started":"2025-02-27T17:30:20.595214Z","shell.execute_reply":"2025-02-27T17:30:26.401073Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c75f071741a545919f5f8cf3a3fac1a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"099e3f20a474405a965da8ecfd1bd534"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72fa5e9f8562401986af7c2287546df5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e2b96f0cb364e6cb05a299ed2af668b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64304ce8c3d1433a9b52e787d402fe0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a710f48feaaf4de6aaf0bd8bb3784443"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n\nAll the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"emotion = pipeline('sentiment-analysis', model='arpanghoshal/EmoRoBERTa', return_all_scores= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:30:26.402837Z","iopub.execute_input":"2025-02-27T17:30:26.403107Z","iopub.status.idle":"2025-02-27T17:30:28.466434Z","shell.execute_reply.started":"2025-02-27T17:30:26.403086Z","shell.execute_reply":"2025-02-27T17:30:28.465722Z"}},"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n\nAll the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\nDevice set to use 0\n/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Example\nprint(train_data.iloc[0]['sentence'], train_data.iloc[0]['label'])\nemotion_labels = emotion(train_data.iloc[0]['sentence'])\npd.DataFrame(emotion_labels[0]).sort_values(by='score', ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:30:28.467535Z","iopub.execute_input":"2025-02-27T17:30:28.467826Z","iopub.status.idle":"2025-02-27T17:30:29.862794Z","shell.execute_reply.started":"2025-02-27T17:30:28.467804Z","shell.execute_reply":"2025-02-27T17:30:29.861919Z"}},"outputs":[{"name":"stdout","text":"Gone are the days when they led the world in recession-busting 1\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"             label     score\n22     realization  0.370921\n27         neutral  0.308373\n9   disappointment  0.295113\n3        annoyance  0.006366\n4         approval  0.003771\n20        optimism  0.002501\n25         sadness  0.002472\n10     disapproval  0.001753\n0       admiration  0.001569\n11         disgust  0.001283\n6        confusion  0.001009\n8           desire  0.000840\n26        surprise  0.000803\n12   embarrassment  0.000647\n24         remorse  0.000479\n7        curiosity  0.000406\n17             joy  0.000406\n18            love  0.000332\n2            anger  0.000157\n21           pride  0.000134\n15       gratitude  0.000129\n23          relief  0.000118\n13      excitement  0.000099\n1        amusement  0.000095\n19     nervousness  0.000081\n5           caring  0.000059\n14            fear  0.000045\n16           grief  0.000040","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22</th>\n      <td>realization</td>\n      <td>0.370921</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>neutral</td>\n      <td>0.308373</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>disappointment</td>\n      <td>0.295113</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>annoyance</td>\n      <td>0.006366</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>approval</td>\n      <td>0.003771</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>optimism</td>\n      <td>0.002501</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>sadness</td>\n      <td>0.002472</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>disapproval</td>\n      <td>0.001753</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>admiration</td>\n      <td>0.001569</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>disgust</td>\n      <td>0.001283</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>confusion</td>\n      <td>0.001009</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>desire</td>\n      <td>0.000840</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>surprise</td>\n      <td>0.000803</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>embarrassment</td>\n      <td>0.000647</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>remorse</td>\n      <td>0.000479</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>curiosity</td>\n      <td>0.000406</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>joy</td>\n      <td>0.000406</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>love</td>\n      <td>0.000332</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>0.000157</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>pride</td>\n      <td>0.000134</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>gratitude</td>\n      <td>0.000129</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>relief</td>\n      <td>0.000118</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>excitement</td>\n      <td>0.000099</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>amusement</td>\n      <td>0.000095</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>nervousness</td>\n      <td>0.000081</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>caring</td>\n      <td>0.000059</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>fear</td>\n      <td>0.000045</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>grief</td>\n      <td>0.000040</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"emotion_array = np.zeros((train_data.shape[0], 28))\n\nfor i, sentence in enumerate(tqdm(train_data['sentence'])):\n    result = emotion(sentence)[0]\n    emotion_array[i] = np.array([list(d.values())[1] for d in result])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion_df_train = pd.DataFrame(emotion_array, columns=[list(d.values())[0] for d in result])\nemotion_df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:51:48.529421Z","iopub.execute_input":"2025-02-27T16:51:48.529875Z","iopub.status.idle":"2025-02-27T16:51:48.550684Z","shell.execute_reply.started":"2025-02-27T16:51:48.529834Z","shell.execute_reply":"2025-02-27T16:51:48.549587Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"   admiration  amusement     anger  annoyance  approval    caring  confusion  \\\n0    0.001569   0.000095  0.000157   0.006366  0.003771  0.000059   0.001009   \n1    0.000021   0.000125  0.000232   0.000431  0.000237  0.001657   0.000134   \n2    0.000049   0.001679  0.003128   0.946737  0.001021  0.000024   0.002792   \n3    0.000052   0.000260  0.000044   0.000441  0.001115  0.000070   0.000278   \n4    0.000269   0.000101  0.000034   0.000148  0.000979  0.000038   0.000029   \n\n   curiosity    desire  disappointment  ...      love  nervousness  optimism  \\\n0   0.000406  0.000840        0.295115  ...  0.000332     0.000081  0.002501   \n1   0.000066  0.000486        0.000117  ...  0.000008     0.000179  0.990538   \n2   0.000393  0.000149        0.000748  ...  0.000012     0.000314  0.000164   \n3   0.000303  0.000099        0.005117  ...  0.000054     0.000472  0.001911   \n4   0.000036  0.000171        0.000067  ...  0.000012     0.000016  0.000761   \n\n      pride  realization    relief   remorse   sadness  surprise   neutral  \n0  0.000134     0.370920  0.000118  0.000479  0.002472  0.000803  0.308372  \n1  0.000081     0.000629  0.000210  0.000638  0.000158  0.000158  0.000849  \n2  0.000124     0.001899  0.000035  0.000024  0.000103  0.000060  0.026365  \n3  0.000040     0.045726  0.000123  0.000073  0.000460  0.861292  0.077762  \n4  0.000014     0.000136  0.000014  0.000022  0.000019  0.000061  0.996816  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>admiration</th>\n      <th>amusement</th>\n      <th>anger</th>\n      <th>annoyance</th>\n      <th>approval</th>\n      <th>caring</th>\n      <th>confusion</th>\n      <th>curiosity</th>\n      <th>desire</th>\n      <th>disappointment</th>\n      <th>...</th>\n      <th>love</th>\n      <th>nervousness</th>\n      <th>optimism</th>\n      <th>pride</th>\n      <th>realization</th>\n      <th>relief</th>\n      <th>remorse</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001569</td>\n      <td>0.000095</td>\n      <td>0.000157</td>\n      <td>0.006366</td>\n      <td>0.003771</td>\n      <td>0.000059</td>\n      <td>0.001009</td>\n      <td>0.000406</td>\n      <td>0.000840</td>\n      <td>0.295115</td>\n      <td>...</td>\n      <td>0.000332</td>\n      <td>0.000081</td>\n      <td>0.002501</td>\n      <td>0.000134</td>\n      <td>0.370920</td>\n      <td>0.000118</td>\n      <td>0.000479</td>\n      <td>0.002472</td>\n      <td>0.000803</td>\n      <td>0.308372</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000021</td>\n      <td>0.000125</td>\n      <td>0.000232</td>\n      <td>0.000431</td>\n      <td>0.000237</td>\n      <td>0.001657</td>\n      <td>0.000134</td>\n      <td>0.000066</td>\n      <td>0.000486</td>\n      <td>0.000117</td>\n      <td>...</td>\n      <td>0.000008</td>\n      <td>0.000179</td>\n      <td>0.990538</td>\n      <td>0.000081</td>\n      <td>0.000629</td>\n      <td>0.000210</td>\n      <td>0.000638</td>\n      <td>0.000158</td>\n      <td>0.000158</td>\n      <td>0.000849</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000049</td>\n      <td>0.001679</td>\n      <td>0.003128</td>\n      <td>0.946737</td>\n      <td>0.001021</td>\n      <td>0.000024</td>\n      <td>0.002792</td>\n      <td>0.000393</td>\n      <td>0.000149</td>\n      <td>0.000748</td>\n      <td>...</td>\n      <td>0.000012</td>\n      <td>0.000314</td>\n      <td>0.000164</td>\n      <td>0.000124</td>\n      <td>0.001899</td>\n      <td>0.000035</td>\n      <td>0.000024</td>\n      <td>0.000103</td>\n      <td>0.000060</td>\n      <td>0.026365</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000052</td>\n      <td>0.000260</td>\n      <td>0.000044</td>\n      <td>0.000441</td>\n      <td>0.001115</td>\n      <td>0.000070</td>\n      <td>0.000278</td>\n      <td>0.000303</td>\n      <td>0.000099</td>\n      <td>0.005117</td>\n      <td>...</td>\n      <td>0.000054</td>\n      <td>0.000472</td>\n      <td>0.001911</td>\n      <td>0.000040</td>\n      <td>0.045726</td>\n      <td>0.000123</td>\n      <td>0.000073</td>\n      <td>0.000460</td>\n      <td>0.861292</td>\n      <td>0.077762</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000269</td>\n      <td>0.000101</td>\n      <td>0.000034</td>\n      <td>0.000148</td>\n      <td>0.000979</td>\n      <td>0.000038</td>\n      <td>0.000029</td>\n      <td>0.000036</td>\n      <td>0.000171</td>\n      <td>0.000067</td>\n      <td>...</td>\n      <td>0.000012</td>\n      <td>0.000016</td>\n      <td>0.000761</td>\n      <td>0.000014</td>\n      <td>0.000136</td>\n      <td>0.000014</td>\n      <td>0.000022</td>\n      <td>0.000019</td>\n      <td>0.000061</td>\n      <td>0.996816</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"train_data_augmented = pd.concat([train_data, emotion_df_train], axis=1)\ntrain_data_augmented.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:52:16.387607Z","iopub.execute_input":"2025-02-27T16:52:16.388054Z","iopub.status.idle":"2025-02-27T16:52:16.412695Z","shell.execute_reply.started":"2025-02-27T16:52:16.388013Z","shell.execute_reply":"2025-02-27T16:52:16.411259Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"                            sentence_id  \\\n0  b9e1635a-72aa-467f-86d6-f56ef09f62c3   \n1  f99b5143-70d2-494a-a2f5-c68f10d09d0a   \n2  4076639c-aa56-4202-ae0f-9d9217f8da68   \n3  b057c366-698e-419d-a284-9b16d835c64e   \n4  a5a9645e-7850-41ba-90a2-5def725cd5b8   \n\n                                            sentence  label  solved_conflict  \\\n0  Gone are the days when they led the world in r...      1             True   \n1  The trend is expected to reverse as soon as ne...      0            False   \n2             But there is the specious point again.      0            False   \n3  He added he wouldnâ€™t be surprised to see a new...      0            False   \n4  Not less government, you see; the same amount ...      1            False   \n\n   admiration  amusement     anger  annoyance  approval    caring  ...  \\\n0    0.001569   0.000095  0.000157   0.006366  0.003771  0.000059  ...   \n1    0.000021   0.000125  0.000232   0.000431  0.000237  0.001657  ...   \n2    0.000049   0.001679  0.003128   0.946737  0.001021  0.000024  ...   \n3    0.000052   0.000260  0.000044   0.000441  0.001115  0.000070  ...   \n4    0.000269   0.000101  0.000034   0.000148  0.000979  0.000038  ...   \n\n       love  nervousness  optimism     pride  realization    relief   remorse  \\\n0  0.000332     0.000081  0.002501  0.000134     0.370920  0.000118  0.000479   \n1  0.000008     0.000179  0.990538  0.000081     0.000629  0.000210  0.000638   \n2  0.000012     0.000314  0.000164  0.000124     0.001899  0.000035  0.000024   \n3  0.000054     0.000472  0.001911  0.000040     0.045726  0.000123  0.000073   \n4  0.000012     0.000016  0.000761  0.000014     0.000136  0.000014  0.000022   \n\n    sadness  surprise   neutral  \n0  0.002472  0.000803  0.308372  \n1  0.000158  0.000158  0.000849  \n2  0.000103  0.000060  0.026365  \n3  0.000460  0.861292  0.077762  \n4  0.000019  0.000061  0.996816  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_id</th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>solved_conflict</th>\n      <th>admiration</th>\n      <th>amusement</th>\n      <th>anger</th>\n      <th>annoyance</th>\n      <th>approval</th>\n      <th>caring</th>\n      <th>...</th>\n      <th>love</th>\n      <th>nervousness</th>\n      <th>optimism</th>\n      <th>pride</th>\n      <th>realization</th>\n      <th>relief</th>\n      <th>remorse</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b9e1635a-72aa-467f-86d6-f56ef09f62c3</td>\n      <td>Gone are the days when they led the world in r...</td>\n      <td>1</td>\n      <td>True</td>\n      <td>0.001569</td>\n      <td>0.000095</td>\n      <td>0.000157</td>\n      <td>0.006366</td>\n      <td>0.003771</td>\n      <td>0.000059</td>\n      <td>...</td>\n      <td>0.000332</td>\n      <td>0.000081</td>\n      <td>0.002501</td>\n      <td>0.000134</td>\n      <td>0.370920</td>\n      <td>0.000118</td>\n      <td>0.000479</td>\n      <td>0.002472</td>\n      <td>0.000803</td>\n      <td>0.308372</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f99b5143-70d2-494a-a2f5-c68f10d09d0a</td>\n      <td>The trend is expected to reverse as soon as ne...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0.000021</td>\n      <td>0.000125</td>\n      <td>0.000232</td>\n      <td>0.000431</td>\n      <td>0.000237</td>\n      <td>0.001657</td>\n      <td>...</td>\n      <td>0.000008</td>\n      <td>0.000179</td>\n      <td>0.990538</td>\n      <td>0.000081</td>\n      <td>0.000629</td>\n      <td>0.000210</td>\n      <td>0.000638</td>\n      <td>0.000158</td>\n      <td>0.000158</td>\n      <td>0.000849</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4076639c-aa56-4202-ae0f-9d9217f8da68</td>\n      <td>But there is the specious point again.</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0.000049</td>\n      <td>0.001679</td>\n      <td>0.003128</td>\n      <td>0.946737</td>\n      <td>0.001021</td>\n      <td>0.000024</td>\n      <td>...</td>\n      <td>0.000012</td>\n      <td>0.000314</td>\n      <td>0.000164</td>\n      <td>0.000124</td>\n      <td>0.001899</td>\n      <td>0.000035</td>\n      <td>0.000024</td>\n      <td>0.000103</td>\n      <td>0.000060</td>\n      <td>0.026365</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b057c366-698e-419d-a284-9b16d835c64e</td>\n      <td>He added he wouldnâ€™t be surprised to see a new...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0.000052</td>\n      <td>0.000260</td>\n      <td>0.000044</td>\n      <td>0.000441</td>\n      <td>0.001115</td>\n      <td>0.000070</td>\n      <td>...</td>\n      <td>0.000054</td>\n      <td>0.000472</td>\n      <td>0.001911</td>\n      <td>0.000040</td>\n      <td>0.045726</td>\n      <td>0.000123</td>\n      <td>0.000073</td>\n      <td>0.000460</td>\n      <td>0.861292</td>\n      <td>0.077762</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a5a9645e-7850-41ba-90a2-5def725cd5b8</td>\n      <td>Not less government, you see; the same amount ...</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0.000269</td>\n      <td>0.000101</td>\n      <td>0.000034</td>\n      <td>0.000148</td>\n      <td>0.000979</td>\n      <td>0.000038</td>\n      <td>...</td>\n      <td>0.000012</td>\n      <td>0.000016</td>\n      <td>0.000761</td>\n      <td>0.000014</td>\n      <td>0.000136</td>\n      <td>0.000014</td>\n      <td>0.000022</td>\n      <td>0.000019</td>\n      <td>0.000061</td>\n      <td>0.996816</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"emotion_array = np.zeros((test_data.shape[0], 28))\n\nfor i, sentence in enumerate(tqdm(test_data['sentence'])):\n    result = emotion(sentence)[0]\n    emotion_array[i] = np.array([list(d.values())[1] for d in result])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:56:29.660925Z","iopub.execute_input":"2025-02-27T16:56:29.661344Z","iopub.status.idle":"2025-02-27T16:58:48.482408Z","shell.execute_reply.started":"2025-02-27T16:56:29.661310Z","shell.execute_reply":"2025-02-27T16:58:48.480675Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 484/484 [02:18<00:00,  3.49it/s]\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"emotion_df_test = pd.DataFrame(emotion_array, columns=[list(d.values())[0] for d in result])\nemotion_df_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:58:48.483965Z","iopub.execute_input":"2025-02-27T16:58:48.484320Z","iopub.status.idle":"2025-02-27T16:58:48.507866Z","shell.execute_reply.started":"2025-02-27T16:58:48.484289Z","shell.execute_reply":"2025-02-27T16:58:48.506047Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"   admiration  amusement     anger  annoyance  approval    caring  confusion  \\\n0    0.000211   0.000236  0.000009   0.000151  0.077252  0.000118   0.000153   \n1    0.000428   0.000470  0.000124   0.000181  0.002491  0.000174   0.000955   \n2    0.000551   0.000124  0.000021   0.000141  0.020175  0.000029   0.000042   \n3    0.000420   0.000101  0.000017   0.000120  0.982816  0.000085   0.000133   \n4    0.000398   0.000266  0.000027   0.000141  0.000731  0.000063   0.000014   \n\n   curiosity    desire  disappointment  ...      love  nervousness  optimism  \\\n0   0.000028  0.000184        0.000205  ...  0.000039     0.000038  0.001292   \n1   0.000099  0.000650        0.000106  ...  0.000465     0.000490  0.001429   \n2   0.000016  0.000033        0.000214  ...  0.000020     0.000011  0.000158   \n3   0.000135  0.000268        0.000049  ...  0.000642     0.000057  0.000740   \n4   0.000032  0.000096        0.000066  ...  0.000027     0.000021  0.000153   \n\n      pride  realization    relief   remorse   sadness  surprise   neutral  \n0  0.000048     0.027911  0.000072  0.000056  0.000050  0.000034  0.891071  \n1  0.000063     0.000649  0.000025  0.000232  0.000235  0.000270  0.981867  \n2  0.000011     0.002110  0.000021  0.000025  0.000056  0.000020  0.974265  \n3  0.000048     0.000641  0.000560  0.000010  0.000016  0.000017  0.010893  \n4  0.000019     0.000096  0.000013  0.000040  0.000051  0.000040  0.996801  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>admiration</th>\n      <th>amusement</th>\n      <th>anger</th>\n      <th>annoyance</th>\n      <th>approval</th>\n      <th>caring</th>\n      <th>confusion</th>\n      <th>curiosity</th>\n      <th>desire</th>\n      <th>disappointment</th>\n      <th>...</th>\n      <th>love</th>\n      <th>nervousness</th>\n      <th>optimism</th>\n      <th>pride</th>\n      <th>realization</th>\n      <th>relief</th>\n      <th>remorse</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000211</td>\n      <td>0.000236</td>\n      <td>0.000009</td>\n      <td>0.000151</td>\n      <td>0.077252</td>\n      <td>0.000118</td>\n      <td>0.000153</td>\n      <td>0.000028</td>\n      <td>0.000184</td>\n      <td>0.000205</td>\n      <td>...</td>\n      <td>0.000039</td>\n      <td>0.000038</td>\n      <td>0.001292</td>\n      <td>0.000048</td>\n      <td>0.027911</td>\n      <td>0.000072</td>\n      <td>0.000056</td>\n      <td>0.000050</td>\n      <td>0.000034</td>\n      <td>0.891071</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000428</td>\n      <td>0.000470</td>\n      <td>0.000124</td>\n      <td>0.000181</td>\n      <td>0.002491</td>\n      <td>0.000174</td>\n      <td>0.000955</td>\n      <td>0.000099</td>\n      <td>0.000650</td>\n      <td>0.000106</td>\n      <td>...</td>\n      <td>0.000465</td>\n      <td>0.000490</td>\n      <td>0.001429</td>\n      <td>0.000063</td>\n      <td>0.000649</td>\n      <td>0.000025</td>\n      <td>0.000232</td>\n      <td>0.000235</td>\n      <td>0.000270</td>\n      <td>0.981867</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000551</td>\n      <td>0.000124</td>\n      <td>0.000021</td>\n      <td>0.000141</td>\n      <td>0.020175</td>\n      <td>0.000029</td>\n      <td>0.000042</td>\n      <td>0.000016</td>\n      <td>0.000033</td>\n      <td>0.000214</td>\n      <td>...</td>\n      <td>0.000020</td>\n      <td>0.000011</td>\n      <td>0.000158</td>\n      <td>0.000011</td>\n      <td>0.002110</td>\n      <td>0.000021</td>\n      <td>0.000025</td>\n      <td>0.000056</td>\n      <td>0.000020</td>\n      <td>0.974265</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000420</td>\n      <td>0.000101</td>\n      <td>0.000017</td>\n      <td>0.000120</td>\n      <td>0.982816</td>\n      <td>0.000085</td>\n      <td>0.000133</td>\n      <td>0.000135</td>\n      <td>0.000268</td>\n      <td>0.000049</td>\n      <td>...</td>\n      <td>0.000642</td>\n      <td>0.000057</td>\n      <td>0.000740</td>\n      <td>0.000048</td>\n      <td>0.000641</td>\n      <td>0.000560</td>\n      <td>0.000010</td>\n      <td>0.000016</td>\n      <td>0.000017</td>\n      <td>0.010893</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000398</td>\n      <td>0.000266</td>\n      <td>0.000027</td>\n      <td>0.000141</td>\n      <td>0.000731</td>\n      <td>0.000063</td>\n      <td>0.000014</td>\n      <td>0.000032</td>\n      <td>0.000096</td>\n      <td>0.000066</td>\n      <td>...</td>\n      <td>0.000027</td>\n      <td>0.000021</td>\n      <td>0.000153</td>\n      <td>0.000019</td>\n      <td>0.000096</td>\n      <td>0.000013</td>\n      <td>0.000040</td>\n      <td>0.000051</td>\n      <td>0.000040</td>\n      <td>0.996801</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"test_data_augmented = pd.concat([test_data, emotion_df_test], axis=1)\ntest_data_augmented.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:58:48.510221Z","iopub.execute_input":"2025-02-27T16:58:48.510608Z","iopub.status.idle":"2025-02-27T16:58:48.542064Z","shell.execute_reply.started":"2025-02-27T16:58:48.510578Z","shell.execute_reply":"2025-02-27T16:58:48.541181Z"}},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"                            sentence_id  \\\n0  44f33601-157a-42ce-aa9f-0f7d305501f2   \n1  6f9e0f53-f76c-432f-bbea-b78400d600b8   \n2  61f93bdc-4c3e-4963-926c-0bbf139b44b9   \n3  902148ec-dda3-4736-b318-0f20c63a1cf3   \n4  065b1996-4b40-4c74-9f62-afb44f69834e   \n\n                                            sentence  label  admiration  \\\n0  Blanco established himself earlier in his care...      0    0.000211   \n1  RULE 13: ARTIFICIAL INTELLIGENCE  Not only thi...      0    0.000428   \n2  The valuation is required by law and the figur...      0    0.000551   \n3  A sip can really hit the spot after a long bik...      1    0.000420   \n4                                       \"Lobster!\"\"\"      0    0.000398   \n\n   amusement     anger  annoyance  approval    caring  confusion  ...  \\\n0   0.000236  0.000009   0.000151  0.077252  0.000118   0.000153  ...   \n1   0.000470  0.000124   0.000181  0.002491  0.000174   0.000955  ...   \n2   0.000124  0.000021   0.000141  0.020175  0.000029   0.000042  ...   \n3   0.000101  0.000017   0.000120  0.982816  0.000085   0.000133  ...   \n4   0.000266  0.000027   0.000141  0.000731  0.000063   0.000014  ...   \n\n       love  nervousness  optimism     pride  realization    relief   remorse  \\\n0  0.000039     0.000038  0.001292  0.000048     0.027911  0.000072  0.000056   \n1  0.000465     0.000490  0.001429  0.000063     0.000649  0.000025  0.000232   \n2  0.000020     0.000011  0.000158  0.000011     0.002110  0.000021  0.000025   \n3  0.000642     0.000057  0.000740  0.000048     0.000641  0.000560  0.000010   \n4  0.000027     0.000021  0.000153  0.000019     0.000096  0.000013  0.000040   \n\n    sadness  surprise   neutral  \n0  0.000050  0.000034  0.891071  \n1  0.000235  0.000270  0.981867  \n2  0.000056  0.000020  0.974265  \n3  0.000016  0.000017  0.010893  \n4  0.000051  0.000040  0.996801  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_id</th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>admiration</th>\n      <th>amusement</th>\n      <th>anger</th>\n      <th>annoyance</th>\n      <th>approval</th>\n      <th>caring</th>\n      <th>confusion</th>\n      <th>...</th>\n      <th>love</th>\n      <th>nervousness</th>\n      <th>optimism</th>\n      <th>pride</th>\n      <th>realization</th>\n      <th>relief</th>\n      <th>remorse</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44f33601-157a-42ce-aa9f-0f7d305501f2</td>\n      <td>Blanco established himself earlier in his care...</td>\n      <td>0</td>\n      <td>0.000211</td>\n      <td>0.000236</td>\n      <td>0.000009</td>\n      <td>0.000151</td>\n      <td>0.077252</td>\n      <td>0.000118</td>\n      <td>0.000153</td>\n      <td>...</td>\n      <td>0.000039</td>\n      <td>0.000038</td>\n      <td>0.001292</td>\n      <td>0.000048</td>\n      <td>0.027911</td>\n      <td>0.000072</td>\n      <td>0.000056</td>\n      <td>0.000050</td>\n      <td>0.000034</td>\n      <td>0.891071</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6f9e0f53-f76c-432f-bbea-b78400d600b8</td>\n      <td>RULE 13: ARTIFICIAL INTELLIGENCE  Not only thi...</td>\n      <td>0</td>\n      <td>0.000428</td>\n      <td>0.000470</td>\n      <td>0.000124</td>\n      <td>0.000181</td>\n      <td>0.002491</td>\n      <td>0.000174</td>\n      <td>0.000955</td>\n      <td>...</td>\n      <td>0.000465</td>\n      <td>0.000490</td>\n      <td>0.001429</td>\n      <td>0.000063</td>\n      <td>0.000649</td>\n      <td>0.000025</td>\n      <td>0.000232</td>\n      <td>0.000235</td>\n      <td>0.000270</td>\n      <td>0.981867</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>61f93bdc-4c3e-4963-926c-0bbf139b44b9</td>\n      <td>The valuation is required by law and the figur...</td>\n      <td>0</td>\n      <td>0.000551</td>\n      <td>0.000124</td>\n      <td>0.000021</td>\n      <td>0.000141</td>\n      <td>0.020175</td>\n      <td>0.000029</td>\n      <td>0.000042</td>\n      <td>...</td>\n      <td>0.000020</td>\n      <td>0.000011</td>\n      <td>0.000158</td>\n      <td>0.000011</td>\n      <td>0.002110</td>\n      <td>0.000021</td>\n      <td>0.000025</td>\n      <td>0.000056</td>\n      <td>0.000020</td>\n      <td>0.974265</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>902148ec-dda3-4736-b318-0f20c63a1cf3</td>\n      <td>A sip can really hit the spot after a long bik...</td>\n      <td>1</td>\n      <td>0.000420</td>\n      <td>0.000101</td>\n      <td>0.000017</td>\n      <td>0.000120</td>\n      <td>0.982816</td>\n      <td>0.000085</td>\n      <td>0.000133</td>\n      <td>...</td>\n      <td>0.000642</td>\n      <td>0.000057</td>\n      <td>0.000740</td>\n      <td>0.000048</td>\n      <td>0.000641</td>\n      <td>0.000560</td>\n      <td>0.000010</td>\n      <td>0.000016</td>\n      <td>0.000017</td>\n      <td>0.010893</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>065b1996-4b40-4c74-9f62-afb44f69834e</td>\n      <td>\"Lobster!\"\"\"</td>\n      <td>0</td>\n      <td>0.000398</td>\n      <td>0.000266</td>\n      <td>0.000027</td>\n      <td>0.000141</td>\n      <td>0.000731</td>\n      <td>0.000063</td>\n      <td>0.000014</td>\n      <td>...</td>\n      <td>0.000027</td>\n      <td>0.000021</td>\n      <td>0.000153</td>\n      <td>0.000019</td>\n      <td>0.000096</td>\n      <td>0.000013</td>\n      <td>0.000040</td>\n      <td>0.000051</td>\n      <td>0.000040</td>\n      <td>0.996801</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"if not os.path.exists('train_en_aug.csv'):\n    train_data_augmented.to_csv('train_en_aug.csv', encoding='UTF-8')\n    test_data_augmented.to_csv('dev_test_en_aug.csv', encoding='UTF-8')\nelse:\n    train_data_augmented = pd.read_csv('train_en_aug.csv', encoding='UTF-8', index_col=0)\n    test_data_augmented = pd.read_csv('dev_test_en_aug.csv', encoding='UTF-8', index_col=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:48.657176Z","iopub.execute_input":"2025-02-27T18:08:48.657494Z","iopub.status.idle":"2025-02-27T18:08:48.687451Z","shell.execute_reply.started":"2025-02-27T18:08:48.657468Z","shell.execute_reply":"2025-02-27T18:08:48.686718Z"}},"outputs":[],"execution_count":148},{"cell_type":"code","source":"def preprocess(text):\n    preprocessed_text = []\n    for t in text.split():\n        if len(t) > 1:\n            t = '@user' if t[0] == '@' and t.count('@') == 1 else t\n            t = 'http' if t.startswith('http') else t\n        preprocessed_text.append(t)\n    return ' '.join(preprocessed_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:50.038278Z","iopub.execute_input":"2025-02-27T18:08:50.038602Z","iopub.status.idle":"2025-02-27T18:08:50.043364Z","shell.execute_reply.started":"2025-02-27T18:08:50.038579Z","shell.execute_reply":"2025-02-27T18:08:50.042357Z"}},"outputs":[],"execution_count":149},{"cell_type":"code","source":"# Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L3700 (with some minor changes removing useless parts)\nclass CustomTrainer(Trainer):\n    def __init__(self, class_weights, device, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # You pass the class weights when instantiating the Trainer\n        self.class_weights = class_weights\n        self.device = device\n\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        if self.label_smoother is not None and \"labels\" in inputs:\n            labels = inputs.pop(\"labels\")\n        else:\n            labels = None\n        outputs = model(**inputs)\n        if self.args.past_index >= 0:\n            self._past = outputs[self.args.past_index]\n\n        if labels is not None:\n            loss = self.label_smoother(outputs, labels)\n        else:\n            # We extract the logits from the model outputs\n            logits = outputs\n            # We compute the loss manually passing the class weights to the loss function\n            criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(self.device)) # Modified to use the class weights\n            # We compute the loss using the modified criterion\n            loss = criterion(logits, inputs['labels'])\n\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:50.172823Z","iopub.execute_input":"2025-02-27T18:08:50.173111Z","iopub.status.idle":"2025-02-27T18:08:50.179133Z","shell.execute_reply.started":"2025-02-27T18:08:50.173090Z","shell.execute_reply":"2025-02-27T18:08:50.178224Z"}},"outputs":[],"execution_count":150},{"cell_type":"code","source":"class CustomEmotionModel(nn.Module):\n    def __init__(self, model_card: str, num_labels: int = 2, num_emotions: int = 28):\n        super(CustomEmotionModel, self).__init__()\n        self.base_model = AutoModel.from_pretrained(model_card)\n        self.emotion_branch = nn.Linear(num_emotions, 128)  # Example: 128 hidden units\n        self.dropout = nn.Dropout(0.1)\n        self.classifier = nn.Linear(self.base_model.config.hidden_size + 128, num_labels)\n\n    def forward(self, input_ids, attention_mask, emotion_features, labels):\n        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]  # Use the CLS token representation\n        \n        # Process emotion features\n        emotion_output = torch.relu(self.emotion_branch(emotion_features))\n        \n        # Concatenate base model output with emotion features\n        combined_output = torch.cat((pooled_output, emotion_output), dim=1)\n        \n        # Apply dropout and classification layer\n        combined_output = self.dropout(combined_output)\n        logits = self.classifier(combined_output)\n        print(logits.shape)\n        \n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:14:30.292133Z","iopub.execute_input":"2025-02-27T18:14:30.292486Z","iopub.status.idle":"2025-02-27T18:14:30.298428Z","shell.execute_reply.started":"2025-02-27T18:14:30.292460Z","shell.execute_reply":"2025-02-27T18:14:30.297443Z"}},"outputs":[],"execution_count":167},{"cell_type":"code","source":"train_data_augmented['all_emotions'] = train_data_augmented[train_data_augmented.columns[-28:]].apply(lambda x: np.array(x.values, dtype=np.float32), axis=1)\ntest_data_augmented['all_emotions'] = test_data_augmented[test_data_augmented.columns[-28:]].apply(lambda x: np.array(x.values, dtype=np.float32), axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:51.452501Z","iopub.execute_input":"2025-02-27T18:08:51.452919Z","iopub.status.idle":"2025-02-27T18:08:51.468073Z","shell.execute_reply.started":"2025-02-27T18:08:51.452891Z","shell.execute_reply":"2025-02-27T18:08:51.467493Z"}},"outputs":[],"execution_count":152},{"cell_type":"code","source":"train_dl = Dataset.from_pandas(train_data_augmented)\ntest_dl = Dataset.from_pandas(test_data_augmented)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:53.188569Z","iopub.execute_input":"2025-02-27T18:08:53.188872Z","iopub.status.idle":"2025-02-27T18:08:53.245840Z","shell.execute_reply.started":"2025-02-27T18:08:53.188850Z","shell.execute_reply":"2025-02-27T18:08:53.245189Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"def tokenize_and_prepare(texts):\n    tokenized = tokenizer(texts['sentence'])\n    return {**tokenized, 'emotion_features': texts['all_emotions']}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:54.235135Z","iopub.execute_input":"2025-02-27T18:08:54.235454Z","iopub.status.idle":"2025-02-27T18:08:54.239134Z","shell.execute_reply.started":"2025-02-27T18:08:54.235429Z","shell.execute_reply":"2025-02-27T18:08:54.238362Z"}},"outputs":[],"execution_count":154},{"cell_type":"code","source":"train_dl = train_dl.map(tokenize_and_prepare, batched=True)\ntest_dl = test_dl.map(tokenize_and_prepare, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:54.958519Z","iopub.execute_input":"2025-02-27T18:08:54.958823Z","iopub.status.idle":"2025-02-27T18:08:55.164731Z","shell.execute_reply.started":"2025-02-27T18:08:54.958800Z","shell.execute_reply":"2025-02-27T18:08:55.163818Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/830 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"877f2c002a6748b29d8ec6a86a14accf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98cf6f1d03144330adc6bc45dc4e57aa"}},"metadata":{}}],"execution_count":155},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:55.807388Z","iopub.execute_input":"2025-02-27T18:08:55.807718Z","iopub.status.idle":"2025-02-27T18:08:55.811513Z","shell.execute_reply.started":"2025-02-27T18:08:55.807696Z","shell.execute_reply":"2025-02-27T18:08:55.810546Z"}},"outputs":[],"execution_count":156},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=f'model',                 \n    learning_rate=5e-6,\n    per_device_train_batch_size=16,         \n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=1e-4,\n    eval_strategy=\"epoch\",       \n    save_strategy=\"no\",           \n    #save_safetensors=True,\n    #load_best_model_at_end=True,\n    report_to='none',\n    seed=SEED,\n    data_seed=SEED\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:14:33.238802Z","iopub.execute_input":"2025-02-27T18:14:33.239088Z","iopub.status.idle":"2025-02-27T18:14:33.266344Z","shell.execute_reply.started":"2025-02-27T18:14:33.239066Z","shell.execute_reply":"2025-02-27T18:14:33.265661Z"}},"outputs":[],"execution_count":168},{"cell_type":"code","source":"class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_data['label']), y=train_data['label'])\nclass_weights = torch.tensor(class_weights, dtype=torch.float32)\nclass_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:14:33.414913Z","iopub.execute_input":"2025-02-27T18:14:33.415140Z","iopub.status.idle":"2025-02-27T18:14:33.423744Z","shell.execute_reply.started":"2025-02-27T18:14:33.415122Z","shell.execute_reply":"2025-02-27T18:14:33.423044Z"}},"outputs":[{"execution_count":169,"output_type":"execute_result","data":{"text/plain":"tensor([0.7801, 1.3926])"},"metadata":{}}],"execution_count":169},{"cell_type":"code","source":"model_card = \"cardiffnlp/twitter-roberta-base-2022-154m\"\ntokenizer = AutoTokenizer.from_pretrained(model_card, use_Fast=False)\nmodel = CustomEmotionModel(model_card, num_labels = 2, num_emotions=28)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:14:33.624098Z","iopub.execute_input":"2025-02-27T18:14:33.624373Z","iopub.status.idle":"2025-02-27T18:14:34.307484Z","shell.execute_reply.started":"2025-02-27T18:14:33.624345Z","shell.execute_reply":"2025-02-27T18:14:34.306437Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-2022-154m and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":170},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dl,\n    eval_dataset=test_dl,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    class_weights=class_weights,\n    device=device,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:14:34.309236Z","iopub.execute_input":"2025-02-27T18:14:34.309540Z","iopub.status.idle":"2025-02-27T18:14:34.502338Z","shell.execute_reply.started":"2025-02-27T18:14:34.309504Z","shell.execute_reply":"2025-02-27T18:14:34.501662Z"}},"outputs":[],"execution_count":171},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:14:35.585194Z","iopub.execute_input":"2025-02-27T18:14:35.585522Z","iopub.status.idle":"2025-02-27T18:14:44.320087Z","shell.execute_reply.started":"2025-02-27T18:14:35.585495Z","shell.execute_reply":"2025-02-27T18:14:44.318931Z"}},"outputs":[{"name":"stdout","text":"torch.Size([16, 2])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='53' max='520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 53/520 00:06 < 01:01, 7.63 it/s, Epoch 1/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [31/31 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"torch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([14, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([16, 2])\ntorch.Size([4, 2])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-172-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3045\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4050\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4051\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4052\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4053\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4338\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"losses\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_losses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4339\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_inputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"inputs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4340\u001b[0;31m             metrics = self.compute_metrics(\n\u001b[0m\u001b[1;32m   4341\u001b[0m                 \u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4342\u001b[0m             )\n","\u001b[0;32m<ipython-input-122-772e074c39ca>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(output_info)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \"\"\"\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [484, 453]"],"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [484, 453]","output_type":"error"}],"execution_count":172},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}