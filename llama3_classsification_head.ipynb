{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10881030,"sourceType":"datasetVersion","datasetId":6742324}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install torch tensorboard\n%pip install  transformers datasets accelerate evaluate bitsandbytes huggingface_hub trl peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:06.368086Z","iopub.execute_input":"2025-03-05T09:49:06.368347Z","iopub.status.idle":"2025-03-05T09:49:17.804949Z","shell.execute_reply.started":"2025-03-05T09:49:06.368327Z","shell.execute_reply":"2025-03-05T09:49:17.803726Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\nCollecting trl\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: trl, evaluate, bitsandbytes\nSuccessfully installed bitsandbytes-0.45.3 evaluate-0.4.3 trl-0.15.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.kill(os.getpid(), 9)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-05T09:49:18.170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport functools\nimport csv\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom pathlib import Path\nimport torch.nn.functional as F\nimport evaluate\nfrom huggingface_hub import notebook_login\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n\nfrom scipy.stats import pearsonr\nfrom datasets import Dataset, DatasetDict\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:26.559520Z","iopub.execute_input":"2025-03-05T09:49:26.559835Z","iopub.status.idle":"2025-03-05T09:49:48.982327Z","shell.execute_reply.started":"2025-03-05T09:49:26.559805Z","shell.execute_reply":"2025-03-05T09:49:48.981645Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data_folder = '/kaggle/input/clef2025-checkthat/data' # data\ndataset = pd.DataFrame(columns=['sentence_id','sentence','label','lang','split'])\n\nfor language in os.listdir(data_folder):\n    for filename in os.listdir(f\"{data_folder}{os.sep}{language}\"):\n        if '.tsv' in filename:\n            abs_path = f\"{data_folder}{os.sep}{language}{os.sep}{filename}\"\n            df = pd.read_csv(abs_path, sep='\\t', quoting=csv.QUOTE_NONE)\n            if 'solved_conflict' in df.columns:\n                df.drop(columns=['solved_conflict'], inplace=True)\n            df['lang'] = language\n            df['split'] = Path(filename).stem\n            dataset = pd.concat([dataset, df], axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:48.983378Z","iopub.execute_input":"2025-03-05T09:49:48.983973Z","iopub.status.idle":"2025-03-05T09:49:49.276942Z","shell.execute_reply.started":"2025-03-05T09:49:48.983949Z","shell.execute_reply":"2025-03-05T09:49:49.276260Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset = dataset[dataset['lang'] == 'english']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:49.278255Z","iopub.execute_input":"2025-03-05T09:49:49.278551Z","iopub.status.idle":"2025-03-05T09:49:49.953155Z","shell.execute_reply.started":"2025-03-05T09:49:49.278529Z","shell.execute_reply":"2025-03-05T09:49:49.952408Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train = dataset[dataset['split'].str.contains('train')].copy()\ndev = dataset[dataset['split'].str.contains('dev')].copy()\ntest = dataset[dataset['split'].str.contains('dev_test')].copy()\n\nprint(f\"Train: {train.shape}\")\nprint(f\"Dev: {dev.shape}\")\nprint(f\"Test: {test.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:49.954378Z","iopub.execute_input":"2025-03-05T09:49:49.954623Z","iopub.status.idle":"2025-03-05T09:49:49.974695Z","shell.execute_reply.started":"2025-03-05T09:49:49.954603Z","shell.execute_reply":"2025-03-05T09:49:49.973870Z"}},"outputs":[{"name":"stdout","text":"Train: (830, 5)\nDev: (946, 5)\nTest: (484, 5)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(f\"Train: {train['label'].value_counts(normalize=True)}\")\nprint(f\"Dev: {dev['label'].value_counts(normalize=True)}\")\nprint(f\"Test: {test['label'].value_counts(normalize=True)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:49.975404Z","iopub.execute_input":"2025-03-05T09:49:49.975678Z","iopub.status.idle":"2025-03-05T09:49:49.993946Z","shell.execute_reply.started":"2025-03-05T09:49:49.975656Z","shell.execute_reply":"2025-03-05T09:49:49.993182Z"}},"outputs":[{"name":"stdout","text":"Train: label\nOBJ     0.640964\nSUBJ    0.359036\nName: proportion, dtype: float64\nDev: label\nOBJ     0.617336\nSUBJ    0.382664\nName: proportion, dtype: float64\nTest: label\nOBJ     0.747934\nSUBJ    0.252066\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train.loc[:, 'label'] = train['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\ndev.loc[:, 'label'] = dev['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\ntest.loc[:, 'label'] = test['label'].apply(lambda x: 0 if x == 'OBJ' else 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:49.994669Z","iopub.execute_input":"2025-03-05T09:49:49.994897Z","iopub.status.idle":"2025-03-05T09:49:50.013987Z","shell.execute_reply.started":"2025-03-05T09:49:49.994872Z","shell.execute_reply":"2025-03-05T09:49:50.013112Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train['label'] = train['label'].astype(int)\ndev['label'] = dev['label'].astype(int)\ntest['label'] = test['label'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:50.014774Z","iopub.execute_input":"2025-03-05T09:49:50.014985Z","iopub.status.idle":"2025-03-05T09:49:50.029942Z","shell.execute_reply.started":"2025-03-05T09:49:50.014966Z","shell.execute_reply":"2025-03-05T09:49:50.029322Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:50.031880Z","iopub.execute_input":"2025-03-05T09:49:50.032157Z","iopub.status.idle":"2025-03-05T09:49:50.061295Z","shell.execute_reply.started":"2025-03-05T09:49:50.032107Z","shell.execute_reply":"2025-03-05T09:49:50.060631Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                            sentence_id  \\\n0  b9e1635a-72aa-467f-86d6-f56ef09f62c3   \n1  f99b5143-70d2-494a-a2f5-c68f10d09d0a   \n2  4076639c-aa56-4202-ae0f-9d9217f8da68   \n3  b057c366-698e-419d-a284-9b16d835c64e   \n4  a5a9645e-7850-41ba-90a2-5def725cd5b8   \n\n                                            sentence  label     lang     split  \n0  Gone are the days when they led the world in r...      1  english  train_en  \n1  The trend is expected to reverse as soon as ne...      0  english  train_en  \n2             But there is the specious point again.      0  english  train_en  \n3  He added he wouldn’t be surprised to see a new...      0  english  train_en  \n4  Not less government, you see; the same amount ...      1  english  train_en  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_id</th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>lang</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b9e1635a-72aa-467f-86d6-f56ef09f62c3</td>\n      <td>Gone are the days when they led the world in r...</td>\n      <td>1</td>\n      <td>english</td>\n      <td>train_en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f99b5143-70d2-494a-a2f5-c68f10d09d0a</td>\n      <td>The trend is expected to reverse as soon as ne...</td>\n      <td>0</td>\n      <td>english</td>\n      <td>train_en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4076639c-aa56-4202-ae0f-9d9217f8da68</td>\n      <td>But there is the specious point again.</td>\n      <td>0</td>\n      <td>english</td>\n      <td>train_en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b057c366-698e-419d-a284-9b16d835c64e</td>\n      <td>He added he wouldn’t be surprised to see a new...</td>\n      <td>0</td>\n      <td>english</td>\n      <td>train_en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a5a9645e-7850-41ba-90a2-5def725cd5b8</td>\n      <td>Not less government, you see; the same amount ...</td>\n      <td>1</td>\n      <td>english</td>\n      <td>train_en</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"notebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:50.062521Z","iopub.execute_input":"2025-03-05T09:49:50.062808Z","iopub.status.idle":"2025-03-05T09:49:50.080238Z","shell.execute_reply.started":"2025-03-05T09:49:50.062779Z","shell.execute_reply":"2025-03-05T09:49:50.079178Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"487abe523ac443bdb2d229c4d4a83e60"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Converting pandas DataFrames into Hugging Face Dataset objects:\ndf_train = Dataset.from_pandas(train.drop(['sentence_id', 'lang', 'split'],axis=1).reset_index(drop=True))\ndf_dev = Dataset.from_pandas(dev.drop(['sentence_id', 'lang', 'split'],axis=1).reset_index(drop=True))\ndf_test = Dataset.from_pandas(test.drop(['sentence_id', 'lang', 'split'],axis=1).reset_index(drop=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:49:50.081238Z","iopub.execute_input":"2025-03-05T09:49:50.081440Z","iopub.status.idle":"2025-03-05T09:49:50.112715Z","shell.execute_reply.started":"2025-03-05T09:49:50.081414Z","shell.execute_reply":"2025-03-05T09:49:50.112165Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = DatasetDict({\n    'train': df_train,\n    'dev': df_dev,\n    'test': df_test\n})\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:55:42.959513Z","iopub.execute_input":"2025-03-05T09:55:42.959842Z","iopub.status.idle":"2025-03-05T09:55:42.965590Z","shell.execute_reply.started":"2025-03-05T09:55:42.959818Z","shell.execute_reply":"2025-03-05T09:55:42.964862Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label'],\n        num_rows: 830\n    })\n    dev: Dataset({\n        features: ['sentence', 'label'],\n        num_rows: 946\n    })\n    test: Dataset({\n        features: ['sentence', 'label'],\n        num_rows: 484\n    })\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"df_train[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:55:49.738003Z","iopub.execute_input":"2025-03-05T09:55:49.738322Z","iopub.status.idle":"2025-03-05T09:55:49.744027Z","shell.execute_reply.started":"2025-03-05T09:55:49.738296Z","shell.execute_reply":"2025-03-05T09:55:49.743348Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'sentence': 'Gone are the days when they led the world in recession-busting',\n 'label': 1}"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"train.label.value_counts(normalize=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:50:34.320556Z","iopub.execute_input":"2025-03-05T09:50:34.320891Z","iopub.status.idle":"2025-03-05T09:50:34.329041Z","shell.execute_reply.started":"2025-03-05T09:50:34.320857Z","shell.execute_reply":"2025-03-05T09:50:34.328375Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"label\n0    0.640964\n1    0.359036\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"class_weights=(1/train.label.value_counts(normalize=True).sort_index()).tolist()\nclass_weights=torch.tensor(class_weights)\nclass_weights=class_weights/class_weights.sum()\nclass_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:50:34.836451Z","iopub.execute_input":"2025-03-05T09:50:34.836781Z","iopub.status.idle":"2025-03-05T09:50:34.911135Z","shell.execute_reply.started":"2025-03-05T09:50:34.836752Z","shell.execute_reply":"2025-03-05T09:50:34.910492Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([0.3590, 0.6410])"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model_name = \"meta-llama/Llama-3.2-1B\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:50:35.449607Z","iopub.execute_input":"2025-03-05T09:50:35.449909Z","iopub.status.idle":"2025-03-05T09:50:35.453823Z","shell.execute_reply.started":"2025-03-05T09:50:35.449881Z","shell.execute_reply":"2025-03-05T09:50:35.452640Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit = True, # enable 4-bit quantization\n    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n)\n\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:50:39.747835Z","iopub.execute_input":"2025-03-05T09:50:39.748154Z","iopub.status.idle":"2025-03-05T09:50:39.753995Z","shell.execute_reply.started":"2025-03-05T09:50:39.748107Z","shell.execute_reply":"2025-03-05T09:50:39.753170Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=2\n)\n\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:51:04.120926Z","iopub.execute_input":"2025-03-05T09:51:04.121289Z","iopub.status.idle":"2025-03-05T09:51:35.098345Z","shell.execute_reply.started":"2025-03-05T09:51:04.121258Z","shell.execute_reply":"2025-03-05T09:51:35.097470Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de9a3afb460c4ee8a287b0bc7e297d8a"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebc571c46be24df4adfb7cac21f75a4f"}},"metadata":{}},{"name":"stderr","text":"Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"LlamaForSequenceClassification(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 2048)\n    (layers): ModuleList(\n      (0-15): 16 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n          (v_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (score): Linear(in_features=2048, out_features=2, bias=False)\n)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:52:35.669527Z","iopub.execute_input":"2025-03-05T09:52:35.669835Z","iopub.status.idle":"2025-03-05T09:52:35.691178Z","shell.execute_reply.started":"2025-03-05T09:52:35.669811Z","shell.execute_reply":"2025-03-05T09:52:35.690499Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"LlamaForSequenceClassification(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 2048)\n    (layers): ModuleList(\n      (0-15): 16 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n          (v_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (score): Linear(in_features=2048, out_features=2, bias=False)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:52:41.415607Z","iopub.execute_input":"2025-03-05T09:52:41.415897Z","iopub.status.idle":"2025-03-05T09:52:41.536434Z","shell.execute_reply.started":"2025-03-05T09:52:41.415873Z","shell.execute_reply":"2025-03-05T09:52:41.535777Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): LlamaForSequenceClassification(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 2048)\n        (layers): ModuleList(\n          (0-15): 16 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=512, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=512, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (score): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=2048, out_features=2, bias=False)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=2048, out_features=2, bias=False)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:52:49.814718Z","iopub.execute_input":"2025-03-05T09:52:49.815029Z","iopub.status.idle":"2025-03-05T09:52:51.760187Z","shell.execute_reply.started":"2025-03-05T09:52:49.815003Z","shell.execute_reply":"2025-03-05T09:52:51.759202Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ef35081772548f183b508067493a985"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3842b12adcc84701afbd1efaad84cbec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"711d37790cb6434ea9e69bc9d451f43e"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:52:56.998432Z","iopub.execute_input":"2025-03-05T09:52:56.998737Z","iopub.status.idle":"2025-03-05T09:52:57.002760Z","shell.execute_reply.started":"2025-03-05T09:52:56.998715Z","shell.execute_reply":"2025-03-05T09:52:57.001817Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"MAX_LEN = 256\n\ndef llama_preprocessing_function(examples):\n    return tokenizer(examples['sentence'], truncation=True, max_length=MAX_LEN)\n\ntokenized_datasets = dataset.map(llama_preprocessing_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:56:48.937711Z","iopub.execute_input":"2025-03-05T09:56:48.938000Z","iopub.status.idle":"2025-03-05T09:56:49.620103Z","shell.execute_reply.started":"2025-03-05T09:56:48.937975Z","shell.execute_reply":"2025-03-05T09:56:49.619110Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/830 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ae57f06367b45a088f04bad2bdcd617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/946 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae9e1e50052e41b9b2f773973e564665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/484 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b34ff2d1d05480cb033406c4a2ca685"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:57:30.173808Z","iopub.execute_input":"2025-03-05T09:57:30.174140Z","iopub.status.idle":"2025-03-05T09:57:30.178086Z","shell.execute_reply.started":"2025-03-05T09:57:30.174097Z","shell.execute_reply":"2025-03-05T09:57:30.177216Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n\n    try:\n        # it's a classification task, take the argmax\n        predictions_processed = np.argmax(predictions, axis=1)\n\n\n        f1 = f1_score(labels, predictions, average='macro')\n        \n        return {'f1': f1}\n    except Exception as e:\n        print(f\"Error in compute_metrics: {e}\")\n        return {'f1': None}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:58:40.091697Z","iopub.execute_input":"2025-03-05T09:58:40.092040Z","iopub.status.idle":"2025-03-05T09:58:40.097050Z","shell.execute_reply.started":"2025-03-05T09:58:40.092010Z","shell.execute_reply":"2025-03-05T09:58:40.096319Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}