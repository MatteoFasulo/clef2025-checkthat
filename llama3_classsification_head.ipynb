{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:06.368347Z",
     "iopub.status.busy": "2025-03-05T09:49:06.368086Z",
     "iopub.status.idle": "2025-03-05T09:49:17.804949Z",
     "shell.execute_reply": "2025-03-05T09:49:17.803726Z",
     "shell.execute_reply.started": "2025-03-05T09:49:06.368327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /workspace/.miniconda3/lib/python3.11/site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: datasets in /workspace/.miniconda3/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: accelerate in /workspace/.miniconda3/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: evaluate in /workspace/.miniconda3/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: bitsandbytes in /workspace/.miniconda3/lib/python3.11/site-packages (0.45.3)\n",
      "Requirement already satisfied: scikit-learn in /workspace/.miniconda3/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: huggingface_hub in /workspace/.miniconda3/lib/python3.11/site-packages (0.29.1)\n",
      "Requirement already satisfied: trl in /workspace/.miniconda3/lib/python3.11/site-packages (0.15.2)\n",
      "Requirement already satisfied: peft in /workspace/.miniconda3/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: ipywidgets in /workspace/.miniconda3/lib/python3.11/site-packages (8.1.5)\n",
      "Requirement already satisfied: transformers[torch] in /workspace/.miniconda3/lib/python3.11/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.miniconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /workspace/.miniconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /workspace/.miniconda3/lib/python3.11/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /workspace/.miniconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /workspace/.miniconda3/lib/python3.11/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /workspace/.miniconda3/lib/python3.11/site-packages (from transformers[torch]) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /workspace/.miniconda3/lib/python3.11/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /workspace/.miniconda3/lib/python3.11/site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in /workspace/.miniconda3/lib/python3.11/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /workspace/.miniconda3/lib/python3.11/site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /workspace/.miniconda3/lib/python3.11/site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /workspace/.miniconda3/lib/python3.11/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /workspace/.miniconda3/lib/python3.11/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: xxhash in /workspace/.miniconda3/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /workspace/.miniconda3/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /workspace/.miniconda3/lib/python3.11/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: psutil in /workspace/.miniconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: rich in /workspace/.miniconda3/lib/python3.11/site-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: comm>=0.1.3 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspace/.miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /workspace/.miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspace/.miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /workspace/.miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: decorator in /workspace/.miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /workspace/.miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /workspace/.miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /workspace/.miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.11/site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.miniconda3/lib/python3.11/site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.11/site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/.miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/.miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /workspace/.miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /workspace/.miniconda3/lib/python3.11/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.miniconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /workspace/.miniconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /workspace/.miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /workspace/.miniconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /workspace/.miniconda3/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/.miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: executing in /workspace/.miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /workspace/.miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /workspace/.miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers[torch] datasets accelerate evaluate bitsandbytes scikit-learn huggingface_hub trl peft ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-05T09:49:18.170Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:26.559835Z",
     "iopub.status.busy": "2025-03-05T09:49:26.559520Z",
     "iopub.status.idle": "2025-03-05T09:49:48.982327Z",
     "shell.execute_reply": "2025-03-05T09:49:48.981645Z",
     "shell.execute_reply.started": "2025-03-05T09:49:26.559805Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 11:29:36.662638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:48.983973Z",
     "iopub.status.busy": "2025-03-05T09:49:48.983378Z",
     "iopub.status.idle": "2025-03-05T09:49:49.276942Z",
     "shell.execute_reply": "2025-03-05T09:49:49.276260Z",
     "shell.execute_reply.started": "2025-03-05T09:49:48.983949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_folder = '/kaggle/input/clef2025-checkthat/data' # data # /workspace/data\n",
    "dataset = pd.DataFrame(columns=['sentence_id','sentence','label','lang','split'])\n",
    "\n",
    "for language in os.listdir(data_folder):\n",
    "    for filename in os.listdir(f\"{data_folder}{os.sep}{language}\"):\n",
    "        if '.tsv' in filename:\n",
    "            abs_path = f\"{data_folder}{os.sep}{language}{os.sep}{filename}\"\n",
    "            df = pd.read_csv(abs_path, sep='\\t', quoting=csv.QUOTE_NONE)\n",
    "            if 'solved_conflict' in df.columns:\n",
    "                df.drop(columns=['solved_conflict'], inplace=True)\n",
    "            df['lang'] = language\n",
    "            df['split'] = Path(filename).stem\n",
    "            dataset = pd.concat([dataset, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:49.278551Z",
     "iopub.status.busy": "2025-03-05T09:49:49.278255Z",
     "iopub.status.idle": "2025-03-05T09:49:49.953155Z",
     "shell.execute_reply": "2025-03-05T09:49:49.952408Z",
     "shell.execute_reply.started": "2025-03-05T09:49:49.278529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['lang'] == 'english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:49.954623Z",
     "iopub.status.busy": "2025-03-05T09:49:49.954378Z",
     "iopub.status.idle": "2025-03-05T09:49:49.974695Z",
     "shell.execute_reply": "2025-03-05T09:49:49.973870Z",
     "shell.execute_reply.started": "2025-03-05T09:49:49.954603Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (830, 5)\n",
      "Dev: (946, 5)\n",
      "Test: (484, 5)\n"
     ]
    }
   ],
   "source": [
    "train = dataset[dataset['split'].str.contains('train')].copy()\n",
    "dev = dataset[dataset['split'].str.contains('dev')].copy()\n",
    "test = dataset[dataset['split'].str.contains('dev_test')].copy()\n",
    "\n",
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Dev: {dev.shape}\")\n",
    "print(f\"Test: {test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:49.975678Z",
     "iopub.status.busy": "2025-03-05T09:49:49.975404Z",
     "iopub.status.idle": "2025-03-05T09:49:49.993946Z",
     "shell.execute_reply": "2025-03-05T09:49:49.993182Z",
     "shell.execute_reply.started": "2025-03-05T09:49:49.975656Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: label\n",
      "OBJ     0.640964\n",
      "SUBJ    0.359036\n",
      "Name: proportion, dtype: float64\n",
      "Dev: label\n",
      "OBJ     0.617336\n",
      "SUBJ    0.382664\n",
      "Name: proportion, dtype: float64\n",
      "Test: label\n",
      "OBJ     0.747934\n",
      "SUBJ    0.252066\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {train['label'].value_counts(normalize=True)}\")\n",
    "print(f\"Dev: {dev['label'].value_counts(normalize=True)}\")\n",
    "print(f\"Test: {test['label'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:49.994897Z",
     "iopub.status.busy": "2025-03-05T09:49:49.994669Z",
     "iopub.status.idle": "2025-03-05T09:49:50.013987Z",
     "shell.execute_reply": "2025-03-05T09:49:50.013112Z",
     "shell.execute_reply.started": "2025-03-05T09:49:49.994872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'label'] = train['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n",
    "dev.loc[:, 'label'] = dev['label'].apply(lambda x: 0 if x == 'OBJ' else 1)\n",
    "test.loc[:, 'label'] = test['label'].apply(lambda x: 0 if x == 'OBJ' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:50.014985Z",
     "iopub.status.busy": "2025-03-05T09:49:50.014774Z",
     "iopub.status.idle": "2025-03-05T09:49:50.029942Z",
     "shell.execute_reply": "2025-03-05T09:49:50.029322Z",
     "shell.execute_reply.started": "2025-03-05T09:49:50.014966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train['label'] = train['label'].astype(int)\n",
    "dev['label'] = dev['label'].astype(int)\n",
    "test['label'] = test['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:50.032157Z",
     "iopub.status.busy": "2025-03-05T09:49:50.031880Z",
     "iopub.status.idle": "2025-03-05T09:49:50.061295Z",
     "shell.execute_reply": "2025-03-05T09:49:50.060631Z",
     "shell.execute_reply.started": "2025-03-05T09:49:50.032107Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>lang</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b9e1635a-72aa-467f-86d6-f56ef09f62c3</td>\n",
       "      <td>Gone are the days when they led the world in r...</td>\n",
       "      <td>1</td>\n",
       "      <td>english</td>\n",
       "      <td>train_en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f99b5143-70d2-494a-a2f5-c68f10d09d0a</td>\n",
       "      <td>The trend is expected to reverse as soon as ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>english</td>\n",
       "      <td>train_en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4076639c-aa56-4202-ae0f-9d9217f8da68</td>\n",
       "      <td>But there is the specious point again.</td>\n",
       "      <td>0</td>\n",
       "      <td>english</td>\n",
       "      <td>train_en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b057c366-698e-419d-a284-9b16d835c64e</td>\n",
       "      <td>He added he wouldn’t be surprised to see a new...</td>\n",
       "      <td>0</td>\n",
       "      <td>english</td>\n",
       "      <td>train_en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a5a9645e-7850-41ba-90a2-5def725cd5b8</td>\n",
       "      <td>Not less government, you see; the same amount ...</td>\n",
       "      <td>1</td>\n",
       "      <td>english</td>\n",
       "      <td>train_en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sentence_id   \n",
       "0  b9e1635a-72aa-467f-86d6-f56ef09f62c3  \\\n",
       "1  f99b5143-70d2-494a-a2f5-c68f10d09d0a   \n",
       "2  4076639c-aa56-4202-ae0f-9d9217f8da68   \n",
       "3  b057c366-698e-419d-a284-9b16d835c64e   \n",
       "4  a5a9645e-7850-41ba-90a2-5def725cd5b8   \n",
       "\n",
       "                                            sentence  label     lang     split  \n",
       "0  Gone are the days when they led the world in r...      1  english  train_en  \n",
       "1  The trend is expected to reverse as soon as ne...      0  english  train_en  \n",
       "2             But there is the specious point again.      0  english  train_en  \n",
       "3  He added he wouldn’t be surprised to see a new...      0  english  train_en  \n",
       "4  Not less government, you see; the same amount ...      1  english  train_en  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:50.062808Z",
     "iopub.status.busy": "2025-03-05T09:49:50.062521Z",
     "iopub.status.idle": "2025-03-05T09:49:50.080238Z",
     "shell.execute_reply": "2025-03-05T09:49:50.079178Z",
     "shell.execute_reply.started": "2025-03-05T09:49:50.062779Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95043ae84156457b8a4980e1ad201021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:49:50.081440Z",
     "iopub.status.busy": "2025-03-05T09:49:50.081238Z",
     "iopub.status.idle": "2025-03-05T09:49:50.112715Z",
     "shell.execute_reply": "2025-03-05T09:49:50.112165Z",
     "shell.execute_reply.started": "2025-03-05T09:49:50.081414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Converting pandas DataFrames into Hugging Face Dataset objects:\n",
    "df_train = Dataset.from_pandas(train.drop(['sentence_id', 'lang', 'split'],axis=1).reset_index(drop=True))\n",
    "df_dev = Dataset.from_pandas(dev.drop(['sentence_id', 'lang', 'split'],axis=1).reset_index(drop=True))\n",
    "df_test = Dataset.from_pandas(test.drop(['sentence_id', 'lang', 'split'],axis=1).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:55:42.959842Z",
     "iopub.status.busy": "2025-03-05T09:55:42.959513Z",
     "iopub.status.idle": "2025-03-05T09:55:42.965590Z",
     "shell.execute_reply": "2025-03-05T09:55:42.964862Z",
     "shell.execute_reply.started": "2025-03-05T09:55:42.959818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 830\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 946\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 484\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': df_train,\n",
    "    'dev': df_dev,\n",
    "    'test': df_test\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:55:49.738322Z",
     "iopub.status.busy": "2025-03-05T09:55:49.738003Z",
     "iopub.status.idle": "2025-03-05T09:55:49.744027Z",
     "shell.execute_reply": "2025-03-05T09:55:49.743348Z",
     "shell.execute_reply.started": "2025-03-05T09:55:49.738296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Gone are the days when they led the world in recession-busting',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:50:34.320891Z",
     "iopub.status.busy": "2025-03-05T09:50:34.320556Z",
     "iopub.status.idle": "2025-03-05T09:50:34.329041Z",
     "shell.execute_reply": "2025-03-05T09:50:34.328375Z",
     "shell.execute_reply.started": "2025-03-05T09:50:34.320857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.640964\n",
       "1    0.359036\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:50:34.836781Z",
     "iopub.status.busy": "2025-03-05T09:50:34.836451Z",
     "iopub.status.idle": "2025-03-05T09:50:34.911135Z",
     "shell.execute_reply": "2025-03-05T09:50:34.910492Z",
     "shell.execute_reply.started": "2025-03-05T09:50:34.836752Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78007519, 1.39261745])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(dataset['train']['label']), y=dataset['train']['label'])\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:50:35.449909Z",
     "iopub.status.busy": "2025-03-05T09:50:35.449607Z",
     "iopub.status.idle": "2025-03-05T09:50:35.453823Z",
     "shell.execute_reply": "2025-03-05T09:50:35.452640Z",
     "shell.execute_reply.started": "2025-03-05T09:50:35.449881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:50:39.748154Z",
     "iopub.status.busy": "2025-03-05T09:50:39.747835Z",
     "iopub.status.idle": "2025-03-05T09:50:39.753995Z",
     "shell.execute_reply": "2025-03-05T09:50:39.753170Z",
     "shell.execute_reply.started": "2025-03-05T09:50:39.748107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = False, # enable 4-bit quantization\n",
    "    #bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    #bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")\n",
    "\n",
    "#lora_config = LoraConfig(\n",
    "#    r = 16, # the dimension of the low-rank matrices\n",
    "#    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "#    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "#    lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
    "#    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "#    task_type = 'SEQ_CLS'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:51:04.121289Z",
     "iopub.status.busy": "2025-03-05T09:51:04.120926Z",
     "iopub.status.idle": "2025-03-05T09:51:35.098345Z",
     "shell.execute_reply": "2025-03-05T09:51:35.097470Z",
     "shell.execute_reply.started": "2025-03-05T09:51:04.121258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    #quantization_config=quantization_config,\n",
    "    num_labels=2,\n",
    "    id2label={0: 'OBJ', 1: 'SUBJ'}, \n",
    "    label2id={'OBJ': 0, 'SUBJ': 1},\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:52:35.669835Z",
     "iopub.status.busy": "2025-03-05T09:52:35.669527Z",
     "iopub.status.idle": "2025-03-05T09:52:35.691178Z",
     "shell.execute_reply": "2025-03-05T09:52:35.690499Z",
     "shell.execute_reply.started": "2025-03-05T09:52:35.669811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#model = prepare_model_for_kbit_training(model)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:52:41.415897Z",
     "iopub.status.busy": "2025-03-05T09:52:41.415607Z",
     "iopub.status.idle": "2025-03-05T09:52:41.536434Z",
     "shell.execute_reply": "2025-03-05T09:52:41.535777Z",
     "shell.execute_reply.started": "2025-03-05T09:52:41.415873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#model = get_peft_model(model, lora_config)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:52:49.815029Z",
     "iopub.status.busy": "2025-03-05T09:52:49.814718Z",
     "iopub.status.idle": "2025-03-05T09:52:51.760187Z",
     "shell.execute_reply": "2025-03-05T09:52:51.759202Z",
     "shell.execute_reply.started": "2025-03-05T09:52:49.815003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:52:56.998737Z",
     "iopub.status.busy": "2025-03-05T09:52:56.998432Z",
     "iopub.status.idle": "2025-03-05T09:52:57.002760Z",
     "shell.execute_reply": "2025-03-05T09:52:57.001817Z",
     "shell.execute_reply.started": "2025-03-05T09:52:56.998715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:56:48.938000Z",
     "iopub.status.busy": "2025-03-05T09:56:48.937711Z",
     "iopub.status.idle": "2025-03-05T09:56:49.620103Z",
     "shell.execute_reply": "2025-03-05T09:56:49.619110Z",
     "shell.execute_reply.started": "2025-03-05T09:56:48.937975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbdb85b92d140888eccbfb9e2f811b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28248cc8f0c944baa987ed80e4bb3748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f74eb6616914c789adc6f9624650cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 256\n",
    "\n",
    "def llama_preprocessing_function(texts):\n",
    "    return tokenizer(texts['sentence'], padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:57:30.174140Z",
     "iopub.status.busy": "2025-03-05T09:57:30.173808Z",
     "iopub.status.idle": "2025-03-05T09:57:30.178086Z",
     "shell.execute_reply": "2025-03-05T09:57:30.177216Z",
     "shell.execute_reply.started": "2025-03-05T09:57:30.174097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:58:40.092040Z",
     "iopub.status.busy": "2025-03-05T09:58:40.091697Z",
     "iopub.status.idle": "2025-03-05T09:58:40.097050Z",
     "shell.execute_reply": "2025-03-05T09:58:40.096319Z",
     "shell.execute_reply.started": "2025-03-05T09:58:40.092010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    m_prec, m_rec, m_f1, m_s = precision_recall_fscore_support(labels, predictions, average=\"macro\",\n",
    "                                                                zero_division=0)\n",
    "    p_prec, p_rec, p_f1, p_s = precision_recall_fscore_support(labels, predictions, labels=[1],\n",
    "                                                                zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'macro_F1': m_f1,\n",
    "        'macro_P': m_prec,\n",
    "        'macro_R': m_rec,\n",
    "        'SUBJ_F1': p_f1[0],\n",
    "        'SUBJ_P': p_prec[0],\n",
    "        'SUBJ_R': p_rec[0],\n",
    "        'accuracy': acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"/workspace/models\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=5,\n",
    "    #weight_decay=0.1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=1,\n",
    "    #warmup_ratio=0.5,\n",
    "    #load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_F1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    eval_dataset = tokenized_datasets['dev'],\n",
    "    data_collator = collate_fn,\n",
    "    compute_metrics = evaluate_metrics,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 53/260 01:00 < 04:06, 0.84 it/s, Epoch 1/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/60 00:23 < 00:00, 2.43 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2242\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   2243\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2244\u001b[0m         trial\u001b[39m=\u001b[39mtrial,\n\u001b[1;32m   2245\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2246\u001b[0m     )\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/transformers/trainer.py:2639\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 2639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\n\u001b[1;32m   2641\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[1;32m   2642\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2643\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/transformers/trainer.py:3085\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3083\u001b[0m metrics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 3085\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   3086\u001b[0m     is_new_best_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_determine_best_metric(metrics\u001b[39m=\u001b[39mmetrics, trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m   3088\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave_strategy \u001b[39m==\u001b[39m SaveStrategy\u001b[39m.\u001b[39mBEST:\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/transformers/trainer.py:3039\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_evaluate\u001b[39m(\u001b[39mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 3039\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(ignore_keys\u001b[39m=\u001b[39mignore_keys_for_eval)\n\u001b[1;32m   3040\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   3042\u001b[0m     \u001b[39m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/transformers/trainer.py:4105\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4102\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   4104\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4105\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   4106\u001b[0m     eval_dataloader,\n\u001b[1;32m   4107\u001b[0m     description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEvaluation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4108\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[1;32m   4109\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[1;32m   4110\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4111\u001b[0m     ignore_keys\u001b[39m=\u001b[39mignore_keys,\n\u001b[1;32m   4112\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39mmetric_key_prefix,\n\u001b[1;32m   4113\u001b[0m )\n\u001b[1;32m   4115\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   4116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/transformers/trainer.py:4321\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4319\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mpad_across_processes(labels, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, pad_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m   4320\u001b[0m \u001b[39mif\u001b[39;00m logits \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4321\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mpad_across_processes(logits, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, pad_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m   4322\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_logits_for_metrics \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4323\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/accelerate/accelerator.py:2683\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2650\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpad_across_processes\u001b[39m(\u001b[39mself\u001b[39m, tensor, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pad_index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pad_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   2651\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[39m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2653\u001b[0m \u001b[39m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2681\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2683\u001b[0m     \u001b[39mreturn\u001b[39;00m pad_across_processes(tensor, dim\u001b[39m=\u001b[39mdim, pad_index\u001b[39m=\u001b[39mpad_index, pad_first\u001b[39m=\u001b[39mpad_first)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/accelerate/utils/operations.py:408\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m         \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    409\u001b[0m     \u001b[39mexcept\u001b[39;00m DistributedOperationException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    410\u001b[0m         operation \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunction\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mfunction\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/accelerate/utils/operations.py:678\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    675\u001b[0m     new_tensor[indices] \u001b[39m=\u001b[39m tensor\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m recursively_apply(\n\u001b[1;32m    679\u001b[0m     _pad_across_processes, tensor, error_on_other_type\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dim\u001b[39m=\u001b[39mdim, pad_index\u001b[39m=\u001b[39mpad_index, pad_first\u001b[39m=\u001b[39mpad_first\n\u001b[1;32m    680\u001b[0m )\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/accelerate/utils/operations.py:126\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[39melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m func(data, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    127\u001b[0m \u001b[39melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported types (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) passed to `\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`. Only nested list/tuple/dicts of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobjects that are valid for `\u001b[39m\u001b[39m{\u001b[39;00mtest_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` should be passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.11/site-packages/accelerate/utils/operations.py:658\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    655\u001b[0m     dim \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tensor\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    657\u001b[0m \u001b[39m# Gather all sizes\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m size \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(tensor\u001b[39m.\u001b[39mshape, device\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mdevice)[\u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    659\u001b[0m sizes \u001b[39m=\u001b[39m gather(size)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    660\u001b[0m \u001b[39m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/31 00:11 < 00:00, 2.47 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'macro_F1': 0.7227893562972096,\n",
       " 'macro_P': 0.8009254408940107,\n",
       " 'macro_R': 0.6951136672402862,\n",
       " 'SUBJ_F1': 0.5549738219895288,\n",
       " 'SUBJ_P': 0.7681159420289855,\n",
       " 'SUBJ_R': 0.4344262295081967,\n",
       " 'accuracy': 0.8243801652892562}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets['test'])\n",
    "evaluate_metrics((predictions, labels))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6742324,
     "sourceId": 10881030,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
